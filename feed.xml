<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-05-10T00:44:18+00:00</updated><id>/feed.xml</id><title type="html">Michael Jae-Yoon Chung</title><subtitle></subtitle><entry><title type="html">Testing robotics systems</title><link href="/2020/12/16/testing.html" rel="alternate" type="text/html" title="Testing robotics systems" /><published>2020-12-16T08:00:00+00:00</published><updated>2020-12-16T08:00:00+00:00</updated><id>/2020/12/16/testing</id><content type="html" xml:base="/2020/12/16/testing.html"><![CDATA[<p>Testing robotics systems is hard.
Here are my strategies.</p>

<h2 id="unit-and-property-based-testing">Unit and property-based testing</h2>

<p>Robotics systems often consist of layers of application programming interfaces (APIs).
While it is difficult to test the lowest-level API like a ROS hardware driver, but everything above can be tested by simulating responses from a lower-layer API using any unit testing framework such as unittest (python), jest (javascript), gtest (C++).
For example, one could test perception algorithms like tabletop pose detector by simulating input images or point clouds via previously stored data (e.g., benchmark data) or algorithmically generated data.
The testing approach of algorithmically generating data is interesting because it allows <a href="https://medium.com/criteo-labs/introduction-to-property-based-testing-f5236229d237">property-based testing</a>, i.e., generating test cases^1^2.
This requires designing (simple) environment generation algorithms but one could simply use existing algorithms like the ones available in <a href="https://atsushisakai.github.io/PythonRobotics/">PythonRobotics</a>.
The key ideas are (1) testing small and independent layers of APIs using (2) algorithmically generated inputs that one could also easily compute expected outputs.</p>

<p>^1 inspired by model-based UI testing frameworks <br />
^2 Zhoulai Fu and Francisco Martinez Lasaca gave a talk “Experiences with Fuzz Testing ROS Component” that covered a similar approach “fuzz testing” and shared <a href="https://ros2-fuzzer.readthedocs.io/en/latest/">their code</a></p>

<h2 id="sequential-property-based-testing">Sequential property-based testing</h2>

<p>Many robotics algorithms work with sequential data.
For example, think of state estimation, control, motion planning algorithms.
Out of the box, property-based testing tools do not provide creating sequential data.
So the first step to testing time-dependent algorithm is updating property-based testing tools to be able to generate sequential random data.
Creating a sequential sampler that does not dependent on the outputs of testing algorithms is easy (e.g., inputs for state estimation algorithms) but otherwise, one requires to create reactive environments using existing tools like combinators.
At this point, basically one requires to build a tiny simulation environment.
While this sounds daunting, it’s actually not thanks to many existing physics simulation libraries and game programming design patterns (e.g., entity-component systems, etc.).</p>

<p>The second problem is verifying test cases over time.
For example, one might want to check whether the outputs of a state estimation algorithm ever return <code class="language-plaintext highlighter-rouge">null</code> or test if a motion planning algorithm ever returns an invalid pose.
I like to use <a href="https://en.wikipedia.org/wiki/Linear_temporal_logic">linear temporal logic (LTL)</a> to verify such temporal properties due to the LTL’s simplicity.
There are some subtleties of using LTLs with property-based testing tools and I’ll elaborate on those in the future (if I find more time).</p>

<h2 id="physical-integration-testing">Physical integration testing</h2>

<p>Like everything robotics, one must test programs with the real robots in real world at some point.
One approach is integrating continuous integration testing with real robots.
There was <a href="https://roscon.ros.org/2016/presentations/PhysicalContinuousIntegrationSlides.pdf">a great talk</a> about this topic from fetch regarding this topic.
<a href="https://youtu.be/SzHw2PIEIKQ">A more recent talk about AWS Robomaker</a> also touches on this topic, too.</p>

<h2 id="closing-meme">Closing meme</h2>

<p>Testing is important but being ultra-selective about which code to add to a repository is also important because maintenance is hard.</p>

<p><img src="https://raw.githubusercontent.com/dominictarr/push-streams-talk/master/meme.png" />
source: https://github.com/dominictarr/push-streams-talk</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Testing robotics systems is hard. Here are my strategies.]]></summary></entry><entry><title type="html">Finishing Graduate School as a New Dad or: How I Learned to Stop Worrying and be Efficient</title><link href="/2020/11/30/finishing.html" rel="alternate" type="text/html" title="Finishing Graduate School as a New Dad or: How I Learned to Stop Worrying and be Efficient" /><published>2020-11-30T08:00:00+00:00</published><updated>2020-11-30T08:00:00+00:00</updated><id>/2020/11/30/finishing</id><content type="html" xml:base="/2020/11/30/finishing.html"><![CDATA[<p>I was a graduate student when my son was born.
As much as I was euphoric about my son’s arrival, reality hit me hard.
I was not ready.
It was brutal but I pulled through graduate school and here is s selected list of tricks I’ve learned from having been a graduate student parent.</p>

<h2 id="buying-time">Buying time</h2>

<p>Time became one of the scarcest resources.
The first thing I did to buy more time for research was saying “no” to social activities, meetings with no clear goal, not-so-related review requests, side projects, system upgrades, etc. as most parents do.
I decided what activities/projects/commitments to say no to based on my gut feeling.
One big problem with this approach was that I couldn’t tell if I missed interesting and important opportunities that are unforeseeable from the day I said “no”.
I started to explicitly allocate time for explorations and update my goals/plans frequently to adjust my plans based on findings from the explorations[^1].
Doing this became easier as I became more aware of my own work/research velocity, which I gained slowly by rigorously tracking my time usage and goals for each week/month/year.</p>

<p>I still felt like there wasn’t enough time for work hence the second thing I tried was securing money, e.g., by asking family members and applying for financial aids available via my department or university.
I did not know about any financial support opportunities but learned about them as time goes on by talking to a few other graduate student parents that I didn’t know the existence of prior to becoming a dad.</p>

<p>The final trick I learned was delaying tasks[^2].
Delaying tasks is a great trick because often delayed tasks disappear completely due to priority changes.
In the beginning, I delayed tasks that I felt very comfortable delaying, e.g., polishing plots before submitting a paper or renaming variable names in codebase while setting up experiments.
Gradually, I started delaying seemingly more important tasks such as polishing related work sections or optimizing infrastructure/refactoring codebases (for initial submissions) essentially to verify get feedback on the more important content earlier, e.g., the main research direction.
In practice, the most difficult part was knowing what kind of tasks are okay (or not okay) to delay on at first sight; sometimes delaying seemingly not-so-important tasks comes back after becoming a much bigger task.
To mitigate this risk, I started to put some time to identify the worst consequences of delaying a certain task and prepare <em>a</em> plan for the worst outcomes.</p>

<p>[^1] This trick was somewhat inspired by <a href="https://www.productplan.com/glossary/gist-planning/">GIST Planning</a> and <a href="https://spark-public.s3.amazonaws.com/startup/lecture_slides/lecture5-market-wireframing-design.pdf">Startup Engineering</a>.<br />
[^2] <a href="https://www.google.com/search?q=Eisenhower+Matrix&amp;tbm=isch">The Eisenhower matrix</a> is a great task prioritization technique, however, in my experience, applying the technique in practice, specifically, classifying tasks clearly into one of 4 slots, wasn’t trivial and hence had a similar problem.</p>

<h2 id="minimal-viable-product">Minimal viable product</h2>

<p>After trying to buy as much time as possible for about a year or so, I made the following observations:</p>

<ol>
  <li>achieving the last 10~20% takes as much more effort as achieving the first 80~90%</li>
  <li>re-visiting/working on something always takes much more time than the initial take</li>
  <li>there is a huge difference between having something finished vs. not, e.g., at least you get a chance to receive feedback</li>
</ol>

<p>These observations made me want to always shoot for the minimal viable product (MVP).
In the past, I tended to overshoot because I didn’t understand the evaluation criteria well and hence wanted to be “safe” by achieving an arbitrary high quality, which was an extremely expensive approach because of 1. and 3. (sometimes I gave up when a task became too big).
To address this problem, I spent more time on (1) understanding the evaluation metrics well, and (2) prototyping early to feel out the requirements in the context.
After clearly defining the evaluation metrics for the MVP, I found using them to efficiently execute something to the completion super helpful, esp., towards the end when I’m tired.
<!-- Another small trick I used was holding my breath and split once without looking back. --></p>

<h2 id="managing-attention">Managing attention</h2>

<p>After having countless sleepless nights and physically demanding days, I’ve realized the most expensive resource was my attention and not the time.
The quality of my attention was not only dependent on my physiological conditions but also my surrounding environment, e.g., the amount of natural light, my team’s mood, etc.
With everything going on, I usually only had about 2hrs of the peak attention per day; 4hrs if lucky.</p>

<p>To best use this time, I identified the most likely time of the day that I have the best attention and protect that time slot for the most important tasks.
Whenever I face a big task, I would start breaking it down and think about different approaches while I’m away from the desk, e.g., while commuting, picking up or dropping off my son, etc.
Usually, the most important tasks such as core algorithm/system design, initial draft writing, big meeting/presentation, etc. reveal themselves[^3].
These tasks require deeply exploring many ideas with caution to make a big dent towards a knotty problem[^4], so I used my protected time to only work on these tasks.
I used times with a medium level of attention for execution tasks; I used to do execution tasks in the protected hours but with well-thought-out approaches, execution tasks didn’t require as much attention as the core problem-solving tasks.
Finally, everything else, emailing and scheduling, resolving meeting topics, writing down new problem-solving approaches were done on foot, e.g., while watching my son at the park.</p>

<p>[^3] Often, combined smaller tasks such as a task decomposition task combined with an execution task also required my full attention.<br />
[^4] I consider these tasks as combinatorial optimization problems and try to act like well-known algorithms such as branch and bound or iterative deepening when exploring paths to solutions.</p>

<h2 id="closing-thoughts">Closing thoughts</h2>

<p>Even after trying all the different tricks, I still missed countless deadlines and took countless bullets of consequences.
When I felt like I hit my limits, the only thing I could do was changing my mentality.
I accepted my limit, lowered bars for myself, thought about the meaning of what I’m desperately chasing after in the grand skim of things, and try to enjoy the process more.</p>

<p>Time to time, I ask myself–was it all worth it?
As much as I try rewiring my brain to reply with “yes” to that question, I cannot bring back the times I missed with my family and I’ll always feel the guilt of not being around much (physically or mentally) when my son needed me the most.
Yet, I’m working on this blog post while watching my son at a playground.</p>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>I consciously and unconsciously picked up the habits of other parents who I closely worked with and had much more responsibility than me like my grad school advisor <a href="https://homes.cs.washington.edu/~mcakmak/">Maya Cakmak</a>, and my past team leader <a href="http://chfritz.github.io/">Christian Fritz</a>.</p>

<p>I decided to write this blog post when I discovered the existence of similar blog posts from authors I respect:</p>
<ul>
  <li><a href="https://medium.com/bits-and-behavior/how-i-sometimes-achieve-academic-work-life-balance-4bbfc1769820">“How I (sometimes) achieve academic work life balance”</a> by Amy Ko</li>
  <li><a href="https://raymondcheng.net/thoughts/time-management.html">“Time Management”</a> by Raymond Cheng</li>
  <li><a href="https://maxwellforbes.com/posts/appropriate-quality">“Appropriate Quality”</a> by Maxwell Forbes</li>
</ul>

<p>Last but not least, I have to disclose that I relied a lot on my wife who sacrificed her time for watching our son.
This note might change the perspective/legitimacy of all tricks I mentioned above.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I was a graduate student when my son was born. As much as I was euphoric about my son’s arrival, reality hit me hard. I was not ready. It was brutal but I pulled through graduate school and here is s selected list of tricks I’ve learned from having been a graduate student parent.]]></summary></entry><entry><title type="html">Job Searching for an Industry Position after Graduate School</title><link href="/2020/11/15/job.html" rel="alternate" type="text/html" title="Job Searching for an Industry Position after Graduate School" /><published>2020-11-15T08:00:00+00:00</published><updated>2020-11-15T08:00:00+00:00</updated><id>/2020/11/15/job</id><content type="html" xml:base="/2020/11/15/job.html"><![CDATA[<p>Earlier this year, I started to look for a job and one of my friends recommended <a href="https://bharathpbhat.github.io/2020/09/19/laid-off-now-what.html">this post</a> written by <a href="https://twitter.com/bharathpbhat">Bharath</a>, a former Uber ML engineer who also had to find a job earlier-er this year but in a much more stressful situation, i.e., within 60 days.
The blog post was amazing.
I basically followed the author’s process with some adjustments for myself, a human-robot interaction researcher who just finished grad school.
In this post, I’ll talk about my job search experience and my adopted process based on Bharath’s process.</p>

<h2 id="on-identifying-which-rolecompany-to-apply">On identifying which role/company to apply</h2>

<p>For a fresh-out-of-school, human-robot interaction researcher with some experience in software engineering work in the industry, the biggest challenge was people didn’t know what was I good at or what I wanted to do.
A part of it was due to the nature of the human-robot interaction or robotics research field that has a wide range of subfields.
Another part of it was me; I had the roles I wanted to take in mind but I was not sure whether I will be good at it so the companies will hire me for the role.
One of my mentors recommended <a href="https://medium.com/thrive-global/ikigai-the-japanese-secret-to-a-long-and-happy-life-might-just-help-you-live-a-more-fulfilling-9871d01992b7">ikigai</a> for career-related decision making and it helped me take the first pass on identifying which companies to apply.
After that, I decided to apply to a wide range of roles (e.g., Software Development Engineer, Applied Researcher, Product Engineer, etc.) across a wide range of companies (e.g., ~5 people startups to BigCos) to find the right role by interacting with companies.</p>

<p>I started by following “The Process” in the “Reach out to everyone” section in Bharath’s blog.
I made a list of companies, reached out to people related to a target company, iterated those two steps until I had a list of ~20 companies that would talk to me.
I reached out to over 50 people–seniors, juniors, friends, friends of the family, any who would talk to me about a role similar to the ones I identified earlier.
The reaching out process was laborious and sometimes humiliating but it was extremely important in retrospect as it turns out some very interesting roles that were not public were found this way.</p>

<p>Sometimes the “speaking with a hiring manager” step naturally happened and I’ve used Bharath’s notes for preparing myself for those meetings.
Whenever I get to talk to a hiring manager or an employee at the team I want to join, I tried to ask as many questions as possible about the role, e.g., a list of selected questions from related articles like <a href="https://www.indeed.com/career-advice/interviewing/questions-to-ask-a-company">this</a> and <a href="https://angel.co/blog/30-questions-to-ask-before-joining-a-startup">this</a> to really visualize what I would be doing in my 1st year and after.
I also asked some questions about the interview process and interview tips to tailor my preparation to a particular company, if needed.
For example, smaller companies’ interviews were less structured while big companies’ interviews’ were highly structured, e.g., for Amazon, see <a href="https://www.amazon.jobs/en/landing_pages/in-person-interview">this</a>.
After talking to a hiring manager, I was able to gauge 1. how interested the company was in hiring me and 2. what they were looking for (e.g., robotics application building, robotics user interface design, evaluating interactive robot systems, etc).
I was also able to feel out whether I have the experiences and skills they were looking for.
This was extremely useful for narrowing down the list because I was able to ask myself how much effort do I want to put in trying to convince a company why they need me or how quickly I can learn the missing skills.
After this step, the number of companies in my list reduced to ~10.
I followed up with a recruiter or hiring manager to start the first step of the interview process, which usually was a coding interview.</p>

<h2 id="preparing-for-coding-interviews">Preparing for coding interviews</h2>

<p>Coding interviews always scare me.
Following Bharath’s process, I started solving a couple of <a href="https://leetcode.com/">leetcode</a> problems every week, was <a href="https://youtu.be/GbyXxUDVeAo?t=105">being very selective with which leetcode problems to work on</a>, and <a href="https://medium.com/hackernoon/14-patterns-to-ace-any-coding-interview-question-c5bb3357f6ed#9cb9">studied patterns</a> and <a href="https://twitter.com/sunilc_/status/1304722881503395840">categories</a> of coding problems to identify my weakest patterns and categories.
Even after such preparation, I choked during the first couple of coding interviews but was much more comfortable in later coding interviews.
For my coding interviews, most companies used a shared coding platform like <a href="https://coderpad.io/">CoderPad</a> and others asked me to share my desktop screen to see how I code in my own environment; some, usually smaller companies, gave me “homework” or a tiny project to work on.
I liked live-coding interviews with a shared coding platform because it saved my time the most.</p>

<h2 id="preparing-for-system-design-interviews">Preparing for system design interviews</h2>

<p>Bharath said system design interviews were his favorite.
For me, system design interviews were the most difficult.
First, the existing system design interview guidelines (like <a href="https://github.com/donnemartin/system-design-primer">this</a> (free) and <a href="https://www.educative.io/courses/grokking-the-system-design-interview">this</a> (paid)) were not tailored to the robotics problems, and second, I’ve learned that system design interview experiences varied a lot across the companies.
I also had a hard time finding a friend or peer who would act as an interviewer to help me with the preparation.
I started by <a href="https://docs.google.com/document/d/14ePsRiubmrbnK3Pm2ETaA9PYNDun24l8XgGR44ILyC4/edit?usp=sharing">creating robotics system design questions</a> based on existing <a href="https://github.com/donnemartin/system-design-primer#system-design-interview-questions-with-solutions">example system design questions with solutions</a>.
Here are other questions I’ve considered:</p>

<ul>
  <li>Design an object detector for a mobile manipulator robot for pick-up tasks</li>
  <li>Design a collaborative robot manipulator for an assembly task</li>
  <li>Design a teleoperation interface for a mobile robot</li>
</ul>

<p>However, based on my interview experiences, some system design questions I’ve asked required having good intuitions on robotics (or robotics perception or motion planning) algorithms to be able to discuss the trade-offs of using different approaches and practical implications for building robotics systems.
Or an ability to map the questions that seem not-so-related to a robotics problem to a robotics system design problem and discuss the approaches and trade-offs or related issues the interviewers are looking for.
Based on post-interview feedback, the interviewers seemed to look for the interviewee’s ability to clearly <em>communicate</em> to gather requirements, identify a problem, propose multiple approaches, discuss trade-offs, and making calculated decisions–ideally while demonstrating experiences in related, industry-standard tools and frameworks.</p>

<!-- TODO: list more example questions -->

<h2 id="preparing-for-core-concept-interviews">Preparing for core concept interviews</h2>

<p>For me, a very few interviews involved asking about core (robotics) concepts; probably because I only made/pursued a very few research positions.
Here I followed Bharath’s process and created a <a href="https://docs.google.com/document/d/1q3_Vu2BdXFafyGuRM4I1HHtWo-Gd041rvC04FytmG9U/edit?usp=sharing">basic ML &amp; robotics concepts list for myself</a>.
For each algorithm, I asked the following four questions:</p>

<ul>
  <li>What is it?</li>
  <li>How does it work? (time/space complexity?)</li>
  <li>When do you use it?</li>
  <li>What are the limitations? Practical considerations?</li>
  <li>Anything else? (personal experiences and findings, etc.)</li>
</ul>

<h2 id="preparing-for-behavioral-interviews">Preparing for behavioral interviews</h2>

<p>Bharath’s notes helped prepare behavioral interviews.
One strategy I like to emphasize is tailoring stories for an interviewer or company.
Tell stories about technical success stories to engineers, research success stories to researchers, leadership success stories to managers.</p>

<h2 id="closing-notes">Closing notes</h2>

<p>I want to re-emphasize the importance of sourcing many interview opportunities.
My peers recommended doing this as one may not know whether a role is interesting until talking to people in the team (i.e., reading job descriptions are not enough).
Another important factor in hindsight is timing.
I considered job searching in May and June and I could not get any interviews.
I got lucky and was able to delay the search for about 2 months and there were a day and night difference.
Timing is something one may not have control over, but if you do, talk to many people (and use other resources) to see how many opportunities are/will be there in your job search time frame.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Earlier this year, I started to look for a job and one of my friends recommended this post written by Bharath, a former Uber ML engineer who also had to find a job earlier-er this year but in a much more stressful situation, i.e., within 60 days. The blog post was amazing. I basically followed the author’s process with some adjustments for myself, a human-robot interaction researcher who just finished grad school. In this post, I’ll talk about my job search experience and my adopted process based on Bharath’s process.]]></summary></entry><entry><title type="html">Understanding Challenges with Large Robotics System Development</title><link href="/2020/03/07/understanding.html" rel="alternate" type="text/html" title="Understanding Challenges with Large Robotics System Development" /><published>2020-03-07T08:00:00+00:00</published><updated>2020-03-07T08:00:00+00:00</updated><id>/2020/03/07/understanding</id><content type="html" xml:base="/2020/03/07/understanding.html"><![CDATA[<p><em>Originally posted on <a href="https://gitlab.com/mjyc/robosysdev-notes/-/blob/master/post.md">GitLab</a></em></p>

<p>Robotics system development is hard. To understand causes for the robotics system development challenges, I interviewed a few robotics engineers who have been involved in large robotics projects and identified the following themes.</p>

<h2 id="there-arent-many-performant-off-the-shelve-tools">There aren’t many performant off-the-shelve tools</h2>

<p>As the field of robotics is not matured, it is not easy to find performance libraries for perception, manipulation, human-robot interaction that fits your needs. Many existing off-the-shelve code is research code and hence requires expert knowledge, e.g., a user needs to see through undocumented assumptions and limitations. Essentially, identifying whether they will be useful for your problem is an art of itself.</p>

<h2 id="there-arent-many-generalist-robotics-systems-engineers">There aren’t many generalist robotics systems engineers</h2>

<p>Although more robotics educational materials are becoming available, there are not many engineers who can design and implement large robotics systems. Many robotics engineers often focuses on one subfield of robotics engineering such as computer vision or control but does not have much experience with working with the whole system. On the other hands, good systems engineers are often lacks the robotics knowledge and treats robotics libraries as black boxes.</p>

<h2 id="gathering-system-requirements-or-software-specifications-is-not-trivial">Gathering system requirements or software specifications is not trivial</h2>

<p>A robotic system that interact with physical world is complicated and consequences of using such system in real world is hard to predict. This makes the gathering of system requirements or software specifications challenging. Therefore the system specifications are often underspecified which yields brittle or over-prepared systems.</p>

<h2 id="maintenance-and-testing-are-challenging">Maintenance and testing are challenging</h2>

<p>Often existing dev-ops tools are unfit for the robotics system development purposes. For example, robotics data collection, analysis, and visualization are different from those of web services. Testing is especially challenging since setting up a real-world testing environment is not trivial, e.g., a clean “reset” of the real robot testing environment is near impossible or time-consuming. Also, the simulators that are supposed to help with testing do not serve their purpose because of the gap between simulation and reality.</p>

<p>Although the list above is based on a small number of interviews and my personal experience, I hope it to be used as a starting point for brainstorming for solutions. Please let me know if you see missing themes or any comments!</p>

<h3 id="misc">Misc.</h3>

<ul>
  <li><em>Sep, 2021. <a href="https://www.csc.gov.sg/articles/how-to-build-good-software">“How to Build Good Software”</a> - “Why Bad Software Happens to Good People” section felt relevant.</em></li>
  <li><em>Apr, 2021. Found more related papers!</em>
    <ul>
      <li><em><a href="https://arxiv.org/ftp/arxiv/papers/2010/2010.14537.pdf">“State of the Practice and Guidelines for ROS-based System”</a></em></li>
      <li><em><a href="https://arxiv.org/pdf/2004.07368.pdf">“A Study on the Challenges of Using Robotics Simulators for Testing”</a></em></li>
    </ul>
  </li>
  <li><em>While I was writing this post, I learned about this excellent paper <a href="https://github.com/S2-group/icse-seip-2020-replication-package/blob/master/ICSE_SEIP_2020.pdf">“State of the Practice and Guidelines for ROS-based System”</a> and discussions about the paper in <a href="https://discourse.ros.org/t/guidelines-on-how-to-architect-ros-based-systems/12641">the ROS Discourse</a>. The paper is focused on <a href="https://www.ros.org/">ROS</a> yet the high-level goals of it seem similar.</em></li>
  <li><em>The study notes this article is based on are available in <a href="https://github.com/mjyc/robosysdev-notes">github</a> and <a href="https://gitlab.com/mjyc/robosysdev-notes">gitlab</a> repos</em></li>
  <li><em>Thank you! to all those who participated in my interview studies</em></li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Originally posted on GitLab]]></summary></entry><entry><title type="html">Getting started with robotics</title><link href="/2019/12/15/getting.html" rel="alternate" type="text/html" title="Getting started with robotics" /><published>2019-12-15T08:00:00+00:00</published><updated>2019-12-15T08:00:00+00:00</updated><id>/2019/12/15/getting</id><content type="html" xml:base="/2019/12/15/getting.html"><![CDATA[<p>Getting started with robotics is confusing.
Robotics is an interdisciplinary field and people think of many different things when they are trying to learn about it.
For example, google searching “getting started with robotics” gives me the following top three results:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=uw-4K9joFL8">How To Start With Robotics? - YouTube</a></li>
  <li><a href="http://robotsforroboticists.com/getting-started-kids-adults/">Robotics for Kids (and Adults) – Getting Started and How to Progress</a></li>
  <li><a href="https://robots.ieee.org/learn/getting-started/">Getting Started in Robotics - ROBOTS: Your Guide to the World of Robotics</a></li>
</ul>

<p>They talk about learning skills related to the fields of mechanical engineering, electrical engineering, and computer science.
At first, it just felt overwhelming.
Reading each of them slowly again, they were great tutorials especially because they all shared one great message–“learn by doing projects” (<a href="https://www.amazon.com/Robotics-Project-Based-Approach-Lakshmi-Prayaga-ebook/dp/B00PG922M4">there was even a book named with a similar spirit</a>).</p>

<p>I 100% agree with the message, I think people should learn robotics by doing projects.
In fact, I recently shared <a href="https://github.com/mjyc/awesome-robotics-projects">my curated list of opensource (and other) robotics projects</a> for those who are interested in building robots.
Because I’m a programmer by training, one additional suggestion I like to add is “start by working with a simulator”.
Working with hardware is fun but it can be extremely time-consuming so by working with a simulator first you can feel out the robot and identify potential problems early.
Projects like <a href="https://mushr.io/">MuSHR</a> and <a href="https://hackaday.io/project/164992-bobble-bot">bobble-bot</a> are great because they provide robot simulators as well as detailed instructions for building robots.
<a href="https://atsushisakai.github.io/PythonRobotics/">PythonRobotics</a> is another great entry point for learning about robotics algorithms.
The repository contains provide tiny, simple environments for testing the algorithms which are great for learning purposes.
Here is a list of <a href="https://www.ros.org/">ROS</a>-based simulators that I’ve curated in <a href="https://rds.theconstructsim.com/r/mchung/">ROS Development studio</a>, <a href="https://www.theconstructsim.com/rds-ros-development-studio/">a cloud service</a> that allows you to work on ROS projects in a browser.
In a similar spirit, I encourage using a single board computer such as <a href="https://www.raspberrypi.org/">Raspberry Pi</a> or <a href="https://developer.nvidia.com/embedded/learn/tutorials">NVIDIA Jetson products</a> instead of using a microcontroller like <a href="https://www.arduino.cc/">Arduino</a>.
Programming a microcontroller can be fun and it can allow you to develop a solution that is highly tailored to your use case, but for learning purposes, it can become a rabbit hole that prevents you from completing the project you started.
However, if your goal is learning mechanical or electrical engineering my advice (rather opinions) is not for you.</p>

<p>Finally, I believe getting involved with robotics communities is effective for learning.
The below list could be good entry points for learning about software-focused robotics</p>

<ul>
  <li><a href="https://github.com/topics/robotics">github repos with #robotics tag</a></li>
  <li><a href="https://discourse.ros.org/">ROS discourse</a></li>
  <li><a href="https://foxglove.dev/blog">Foxglove blog</a></li>
  <li><a href="https://picknik.ai/blog/">PICKNIK blog</a></li>
  <li><a href="https://developer.nvidia.com/blog/tag/isaac-sim/">Isaac Sim Technical Blog</a></li>
  <li><a href="https://www.duckietown.org/research/ai-driving-olympics">The AI Driving Olympics (AI-DO)</a></li>
  <li><a href="https://www.balena.io/blog">Balena blog</a> - they provide less robotics and more IoT-centric contents</li>
  <li><a href="https://getcruise.com/news">Cruise news</a></li>
  <li><a href="https://github.com/mjyc/awesome-robotics-system-design">Awesome Robotics System Design</a> - where I keep interesting software-focused robotics stuff</li>
</ul>

<p>the list below for learning about electronics-focused robotics</p>

<ul>
  <li><a href="https://www.sparkfun.com/news">sparkfun news</a></li>
  <li><a href="https://blog.adafruit.com/">adafruit blog posts</a></li>
</ul>

<p>and the list below for learning about hardware-focused robotics</p>

<ul>
  <li><a href="https://www.instructables.com/">instructables</a></li>
  <li><a href="https://hackaday.com/">hackaday</a></li>
  <li><a href="https://www.hackster.io/">hackster.io</a></li>
  <li><a href="https://www.onshape.com/en/blog/">onshape blog</a> - <a href="https://hackaday.com/2021/02/28/onshape-to-robot-models-made-easier/">roboticsts love it</a></li>
</ul>

<p>This may be a bit off topic, but since people relate “robotics” with AI/ML computer science research, it might be fun to skim robotics-related papers in open paper review and curated paper list websites:</p>

<ul>
  <li><a href="https://arxiv.org/">https://arxiv.org/</a></li>
  <li><a href="https://openreview.net/">https://openreview.net/</a></li>
  <li><a href="https://paperswithcode.com/">https://paperswithcode.com/</a> - one note: not all researchers are great coders/documenters.</li>
  <li><a href="http://bohg.cs.stanford.edu/list/">http://bohg.cs.stanford.edu/list/</a></li>
</ul>

<p>Talking about skimming, it might be inspiring to skim the class materials from <a href="https://courses.cs.washington.edu/courses/cse478/20wi/">CSE 478: Autonomous Robotics</a>.
Unlike many other class materials, their class slides provide application examples of introduced concepts with an open-source autonomous mobile robot platform <a href="https://mushr.io/">MUSHR</a>.</p>

<p><strong>WARNING</strong> Reading papers and learning class materials can become yet another rabbit hole.
There are endless interesting papers (on surface) or concepts (from class slides) and they can distract you from finishing your project.
What happens is that because you feel achievement/growth and you get temped to keep learning.
Being able to focus on the track and learn only necessary skills (and taking the project to the finish line–and defining the finish line) is a huge challenge/probably the most important skill to learn.</p>

<p>With that said, go explore project ideas, check out robotics communities and start your project!
I believe now is the time to learn about robotics and I hope this blurb can be helpful to aspiring roboticists.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Getting started with robotics is confusing. Robotics is an interdisciplinary field and people think of many different things when they are trying to learn about it. For example, google searching “getting started with robotics” gives me the following top three results:]]></summary></entry><entry><title type="html">Consumer Robots are Dead, Long Live DIY Robots!</title><link href="/2019/06/23/social.html" rel="alternate" type="text/html" title="Consumer Robots are Dead, Long Live DIY Robots!" /><published>2019-06-23T08:00:00+00:00</published><updated>2019-06-23T08:00:00+00:00</updated><id>/2019/06/23/social</id><content type="html" xml:base="/2019/06/23/social.html"><![CDATA[<p>In the span of a year, we have witnessed the death of major consumer robot companies.
What went wrong?
Guy Hoffman, a robotics expert, <a href="https://spectrum.ieee.org/anki-jibo-and-kuri-what-we-can-learn-from-social-robotics-failures">provides a comprehensive summary</a> of possible reasons for the demise of the companies.
To me, the problem was good old over-promise and under-deliver.
I mean, just look at <a href="https://youtu.be/H0h20jRA5M0">this commercial</a> and look at <a href="https://youtu.be/xmntMiJ5zKs">a real robot</a>.
But I also think that there is another problem that is rooted in our culture; when you hear the word “robot”, what comes into your mind?
I think about C-3PO and R2-D2 from Star Wars, The Terminator, WALL-E, Sonny from I, Robot, and Marvin from The Hitchhiker’s Guide to the Galaxy, just to name a few.
Most of these robots are physically more capable than humans  and even emotionally as capable as humans[^1].
After seeing such robots over and over, we expect a robot to be a super awesome friend/servant (or killing machine), and see a commercial like <a href="https://youtu.be/H0h20jRA5M0">this</a> and we get <a href="https://youtu.be/xmntMiJ5zKs">this</a>[^2].
But I digress.</p>

<p>Of course not all consumer robots are dead.
We still have iRobot’s Roomba and Amazon’s Echo/Alexa–if you consider a voice-agent compatible smart speaker a robot.
But for some reason, they don’t feel like a robot.
I nearly gave up on trying to define what the “robot” is and advocating for <a href="https://twitter.com/mjyc_/status/1300898349529182208">not calling anything a “robot”</a>, partially to stop that cultural image of the “robot” mentioned earlier.
But that didn’t work, e.g., I couldn’t stop using the word “robot”.
So I made peace with considering a physical device (e.g., a mobile robot or robot manipulator) that is capable of complex sensing (e.g., computer vision), complex control (e.g., motion planning), and adaptation (e.g., machine learning) a “robot”.
For example, I wouldn’t call industrial manipulators that pick things up from and place things in known locations but I would call a mobile rover that recognizes street signs and avoids pedestrians crossing a road a robot.</p>

<p>Okay, so where do we go from here?
Will we have a “robot” that we can use at home? what will it look like? what will it do?
It’s likely that a big tech company will build something, but I say the time is now for rolling our sleeves up and building home robots ourselves!
It might be difficult but I think it is possible.
First, we need hardware.
We can buy a kit like a TurtleBot or get an open hardware design from one of the Hackaday blog posts or design one from scratch on onshape, if you can.
Second, we’ll need to add electronics.
We can buy a Raspberry Pi or a super fancy GPU or TPU board from <a href="https://developer.nvidia.com/embedded/jetson-nano">NVidia</a> or <a href="https://coral.ai">Google</a>.
I can’t work with microcontrollers but don’t let me stop you.
Finally, software.
There are opensource softwares like ROS, Nvidia Isaac, Apex Autoware, etc.</p>

<p>What should we build?[^3]
That’s a great question.
My approach is reviewing my hobbies and asking how can I use robotics capabilities to make them more interesting.
This usually boils down to adding capabilities like mobility, manipulability, or computer vision to existing things. I tried to build interactive or mobile decorations like interactive lights (e.g., changing ceiling light colors based on locations of detected people) and mobile pots (e.g., moving to different locations at different times).
Another approach is starting from the problem, e.g., by asking what problem can I solve with robotics capabilities?
This approach usually gets blocked by the current limitations of the robotics tech, but some people do come with clear solutions (e.g., limiting the scope of the problem, involving humans, etc.) to make progress.</p>

<p>Honestly though, it isn’t easy to build homemade robots and making them actually useful is near-impossible for a hobbyist.
Although robotics technology is advancing quickly, there are limitations that makes them not as reliable for real world use cases and hardware devices (e.g., high-quality motors) are still pretty expensive.
So why did I suggest to build your own robot?
I wanted the robot lovers to acknowledge the fact that we are building home robots because we just love doing so[^4] and you shouldn’t be discouraged by recent fallings of the robot companies.
Long live DIY robots!</p>

<h3 id="updates">Updates</h3>

<ul>
  <li>2023/05/06 Recently, I heard that <a href="https://techcrunch.com/2023/05/01/neato-robotics-is-being-shut-down-after-18-years/">Neato Robotics was shutting down</a>. Unlike other shutdown news (e.g., <a href="https://www.theverge.com/2023/2/24/23613214/everyday-robots-google-alphabet-shut-down">Everyday Robots shutdown</a>), this news was particularly shocking because I thought robot vacuums sell. Couple other observations since the first draft of this post: (1) new consumer/home robots were announced, e.g., <a href="https://labradorsystems.com/">Labrador</a>, <a href="https://www.aboutamazon.com/news/devices/meet-astro-a-home-robot-unlike-any-other">Amazon Astro</a>, and <a href="https://www.tiktok.com/@arina.bloom/video/7221590486514027818">Matician Matic</a>, (2) there are many open-source or DIY autonomous RC car projects (e.g., <a href="https://f1tenth.org/">F1TENTH</a>, <a href="https://www.duckietown.org/">Duckiebot</a>, <a href="https://aws.amazon.com/deepracer/">DeepRacer</a>, <a href="https://mushr.io/">MuSHR</a>, <a href="https://racecar.mit.edu/">MIT Racecar</a>) appeared, and (3) humanoid robot companies raised $$$, e.g., <a href="https://agilityrobotics.com/news/2022/future-robotics">Agility Robotics</a> and <a href="https://www.figure.ai/">Figure AI</a>.</li>
</ul>

<p>[^1] I love fictions/movies like <a href="https://en.wikipedia.org/wiki/Pluto_(manga)">Pluto</a> or <a href="https://en.wikipedia.org/wiki/Her_(film)">Her</a> that questions the meaning of “human” when robots can be as capable as humans.<br />
[^2] I keep picking on Jibo but I really wanted it to succeed and at this point, I think learning from its mistake is important for roboticists of tomorrow.
<br />
[^3] Also checkout <a href="https://generalrobots.substack.com/p/how-to-pick-a-problem">How to Pick a Problem</a>
[^4] Checkout <a href="https://www.robinsloan.com/notes/home-cooked-app/">AN APP CAN BE A HOME-COOKED MEAL</a> by Robin Sloan</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In the span of a year, we have witnessed the death of major consumer robot companies. What went wrong? Guy Hoffman, a robotics expert, provides a comprehensive summary of possible reasons for the demise of the companies. To me, the problem was good old over-promise and under-deliver. I mean, just look at this commercial and look at a real robot. But I also think that there is another problem that is rooted in our culture; when you hear the word “robot”, what comes into your mind? I think about C-3PO and R2-D2 from Star Wars, The Terminator, WALL-E, Sonny from I, Robot, and Marvin from The Hitchhiker’s Guide to the Galaxy, just to name a few. Most of these robots are physically more capable than humans and even emotionally as capable as humans[^1]. After seeing such robots over and over, we expect a robot to be a super awesome friend/servant (or killing machine), and see a commercial like this and we get this[^2]. But I digress.]]></summary></entry><entry><title type="html">Please help me building a cloud visual SLAM system for cellphones</title><link href="/2019/06/09/please.html" rel="alternate" type="text/html" title="Please help me building a cloud visual SLAM system for cellphones" /><published>2019-06-09T08:00:00+00:00</published><updated>2019-06-09T08:00:00+00:00</updated><id>/2019/06/09/please</id><content type="html" xml:base="/2019/06/09/please.html"><![CDATA[<p><em>Originally published on <a href="https://dev.to/mjyc/please-help-me-building-a-cloud-visual-slam-system-for-cellphones-ine">Dev Community</a></em></p>

<p>Hello hackers, tinkers, webdevs, sysdevs, roboticists, and all coders! I’ve been excited about <a href="https://en.wikipedia.org/wiki/Cloud_robotics">cloud robotics</a>, a field of robotics that utilizes the power of cloud computing, and want to share the excitement with you and suggest a project we can potentially work together. The project that I’m thinking of is “cellphone visual SLAMing”. The idea is to run a visual SLAM system on cloud so mobile devices like a cellphone can build 3D maps by simply uploading camera data to the cloud.</p>

<p>Here are the steps I’m thinking:</p>

<ol>
  <li>Try creating a 3D map using <a href="https://github.com/raulmur/ORB_SLAM2">ORB_SLAM2</a> and desktop camera images.
The main goal of this step is to get comfortable with a visual SLAM library and feel out the limitations.</li>
  <li>Try creating 3D maps using ORB*SLAM2 running on a desktop and cellphone camera images.
ORB_SLAM2 supports <a href="https://www.ros.org/">ROS</a>. So one can easily capture device camera images using <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia">HTML5’s <code class="language-plaintext highlighter-rouge">MediaDevices.getUserMedia()</code></a>, turn them into ROS image messages, and publish them using <a href="https://github.com/RobotWebTools/roslibjs">roslibjs</a> so ORB_SLAM2 can use the images collected from a remote device.</li>
  <li>Run the ORB_SLAM2 to cloud.
I have not tried it, but it seems like it is fairly easy to <a href="https://docs.docker.com/samples/library/ros/">containerize a ROS package and deploy it on cloud</a>.</li>
</ol>

<p>That’s it! Are you interested in trying this idea out? If you have experiences with visual SLAM and have suggestions? Let me know, I’d love to hear your thoughts.</p>

<h3 id="updates">Updates</h3>

<ul>
  <li><em>2021/01/02</em> I have moved on as I don’t get to spend time on tinkering but still think this is a fun project to try one day.</li>
  <li><em>2020/11/23</em> <a href="https://fyusion.com/">Fyusion</a> and <a href="https://canvas.io/">CANVAS</a> seem to provide products with related technologies.</li>
  <li><em>2020/05/02</em> It seems like se2lam github.com/izhengfan/se2lam could be used instead of ORB_SLAM2.</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Originally published on Dev Community]]></summary></entry><entry><title type="html">Collaborating with Undergraduate Students as a Graduate Student in Research</title><link href="/2019/06/04/collaborating.html" rel="alternate" type="text/html" title="Collaborating with Undergraduate Students as a Graduate Student in Research" /><published>2019-06-04T08:00:00+00:00</published><updated>2019-06-04T08:00:00+00:00</updated><id>/2019/06/04/collaborating</id><content type="html" xml:base="/2019/06/04/collaborating.html"><![CDATA[<p>Although there are great blog posts on this topic of “how to work with undergraduate students” from veterans in the field [<a href="https://homes.cs.washington.edu/~mernst/advice/undergrad-research.html">1</a>,<a href="https://www.cs.cornell.edu/~asampson/blog/undergrads.html">2</a>], I have my own take on this topic so here I wrote down the process I came up with from working with truly amazing undergraduate students I met over my graduate school years.</p>

<h4 id="step-1-identify-your-goal">Step 1: Identify your goal.</h4>

<p>First, you should clearly understand what do <em>you</em> want to get out by working with undergraduate students.
Do you need some help on finishing up a small portion of your research project?
Are you excited about your research topic and do you want to have someone else take a look at unexplored ideas?
Do you want to accelerate the growth of your field by outreaching to undergraduate students?
Whatever your goal is, you want to be clear about it so you can prepare an appropriate interview and collaboration strategies.</p>

<p>Note that goals can be updated over time.
Personally, I like to set my initial goal as getting help on a concrete and small subset of my project, then update the goal to help the student to become a researcher–if and only if such goal seems mutually beneficial.</p>

<h4 id="step-15-find-a-student">Step 1.5: Find a student.</h4>

<p>The easiest approach is doing nothing.
In a University setting, motivated undergraduate students will email your advisor or you to get involved in a research project and you should be wanting to work with those motivated students.
The obvious pro of this approach is that you don’t need to do anything.
The downside is that you cannot control the timing and sometimes even the project topic you’ll be collaborating on.
For example, your advisor may email you to work with a student who comes with their own funding and research topic over the summer.</p>

<p>The second easiest approach is attending “undergraduate research fair” type events hosted by your department or University.
This approach gives you more control in timing and the collaboration project topic but requires you to put some effort on preparing materials for the fair and more importantly, I found meeting a suitable or talented student hit-or-miss.</p>

<p>The final approach is asking around.
If you can elaborate kind of students you are looking for clearly, your peers or advisors can be helpful in finding a suitable student for you.
Compare to the “attending research fairs” approach, this approach can help you find “the student” you are looking but with a low probability of actually finding one.</p>

<p>I tend to take both the first and third approaches.
The downside of the two approaches are having no control in the timing but if you have multiple projects going at different stages all the time, you always have a project to collaborate with, so timing becomes less of an issue than finding a talented, passion-sharing student.</p>

<p>Finding a student requires you to have an interview strategy.
For this topic, I highly recommend checking out Michael Ernst’s <a href="https://homes.cs.washington.edu/~mernst/advice/interviewing-undergraduates.html">“Tips for interviewing undergraduates for research”</a>.</p>

<h4 id="step-2-identify-your-students-goal">Step 2: Identify your student’s goal.</h4>

<p>Understanding your student’s goal is as important as understanding your own goal for a healthy collaboration relationship.</p>

<p>From my experience, the most common motivation of the undergraduate students I’ve work with was getting exposed to robotics research.
For the older students who are closer to graduate, they were also motivated by expanding their skill sets to make themselves more attractive to the companies they want to apply to.
There were also some students who wanted to publish an academic paper before they apply to a graduate school to strengthen their application.</p>

<p>I found that it is difficult to identify undergraduate students’ internal motivations from interviews alone.
Most students do not fully understand what their own goals are or interests since they are not fully aware of what they really want or simply because they had not had much experience with robotics research.
Therefore I like to plan the first collaboration project with a student as a “getting to know each other” project.
However, if you don’t have time, e.g., working on a short term project, you will need to rely on your intuition on identifying students’ motivations.</p>

<h4 id="step-3-start-collaborating">Step 3: Start collaborating.</h4>

<p>Your collaboration strategies should be dependent on your and your student’s goals and the agreed collaboration duration.</p>

<p>In general, I like to take a goal-driven collaboration strategy.
For example, I set the goals for students and myself for a certain duration and work towards those goals while helping each other.
This approach particularly worked well for me because by not giving them step-by-step instructions, the students show their original approaches for achieving the assigned project goals as well as their personality.
The approach also allows me to see whether they can learn from demonstrations.
Because we are collaborating, they see what I do to solve complex problems (or the problems that are unfamiliar to them) and give them chance to immediate my approach–if it makes sense.
I focus on demonstrating high-level problem-solving strategies like clearly identifying underspecified goals, breaking down complex goals, and managing one’s time and attention span.
Interestingly, over the years of trying out the goal-driven collaboration, I’ve learned a lot from the students as well.
Many students I met had less experience with the field of robotics, however, some of them were just truly gifted human beings and I could learn a lot from their original way of handling the small research projects give to them.</p>

<p>Sometimes, students are not ready to collaborate at all but you still want to or need to work with them.
In such a case, I give them a small-scoped, independent project and observe what they do.
I ask the following questions to myself to decide whether I want to work with the student for a longer-term:</p>

<ul>
  <li>Can they communicate?</li>
  <li>Can they learn?</li>
  <li>Can they apply the technical skill sets they claimed to have?</li>
  <li>Do they find research interesting?</li>
</ul>

<p>How do you know your student is making progress?
Look at what they do.
They will demonstrate that they have learned the required skill by applying them properly.
They will demonstrate that they are excited about the project by spending time on it over the weekend and by proactive contacting you to show what they have done.</p>

<p>Regardless of taking the goal-driven collaboration approach or the giving independent project approach and because my goal for collaborating with students is getting them involved into the world of research, i.e., finding future peers, I like to give them a snapshot of the graduate student lifestyle by encouraging to participate in lab meetings, research seminars and discussions with peers.
I also encourage them to present the potential impact of the collaboration project in their own words and encourage them to present their work as much as possible–at their class, lab meetings, or even at local meetups.
If they don’t have much time to do research work, I encourage them to use the research project for their graduation requirements, e.g., a project for a project-oriented senior class or senior thesis.</p>

<h4 id="step-4-say-goodbye">Step 4: Say goodbye.</h4>

<p>Most times, students leave the project in less than six months; some graduate, move on to another project, or simply stop working on it.
What about when things are going well?
How do you know when to stop collaborating?
Eventually, when to part away with your student will become obvious.
They will naturally work more independently and even start identifying their own agendas and work towards them, e.g., by working with your advisor directly.
That would be time to stop considering them as an “undergraduate” researcher and treat them like a peer researcher.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Although there are great blog posts on this topic of “how to work with undergraduate students” from veterans in the field [1,2], I have my own take on this topic so here I wrote down the process I came up with from working with truly amazing undergraduate students I met over my graduate school years.]]></summary></entry><entry><title type="html">I hate robots that tell jokes</title><link href="/2019/03/11/hate.html" rel="alternate" type="text/html" title="I hate robots that tell jokes" /><published>2019-03-11T08:00:00+00:00</published><updated>2019-03-11T08:00:00+00:00</updated><id>/2019/03/11/hate</id><content type="html" xml:base="/2019/03/11/hate.html"><![CDATA[<p>I don’t like <a href="https://www.youtube.com/watch?v=kWlL4KjIP4M">robots that tell jokes</a>.
Humor is a complex concept and I don’t think <a href="https://www.theatlantic.com/magazine/archive/2018/03/funny-how/550910/">humans fully understand how humor works</a>.
So trying to make robots say something funny feels wrong.
I don’t like <a href="https://www.youtube.com/watch?v=E1DuJQL8spY">robots that dance</a>.
The robots are not as agile as we humans and every time I see dancing robots, they look like they don’t want to dance but were forced to do it.
But we make them tell jokes or dance <a href="https://www.youtube.com/watch?v=poh5zSsd1rE&amp;t=3s">again</a>, <a href="https://www.youtube.com/watch?v=am1csALyEzE">again</a>, <a href="https://www.youtube.com/watch?v=r2SDVQCzQoA">again</a>, <a href="https://www.youtube.com/watch?v=LiTGaacQ7Og">again</a>, and <a href="https://www.youtube.com/watch?v=kHBcVlqpvZ8&amp;t=1s">again</a>.</p>

<p>Why?</p>

<h3 id="updates">Updates</h3>

<ul>
  <li><em>2021/01/06</em> I found <a href="https://jessicarajko.medium.com/dancing-robots-are-not-about-dance-waiving-goodbye-to-2020-and-popular-exploitations-of-dance-961f57d3ee4c">“These Dancing Robots Are Not About Dance: waiving goodbye to 2020 and popular exploitations”</a> by Jessica Rajko. It helped me understand where my hatred is coming from.</li>
  <li><em>2021/01/03</em> There was (yet another) robot dancing <a href="https://www.youtube.com/watch?v=fn3KWM1kuAw">video</a> posted from Boston Dynamics. I was amazed at Boston Dynamics’ technical achievement but something still bothered me.</li>
  <li><em>2019/11/30</em> Then there are portrait drawing robots [<a href="https://www.youtube.com/watch?v=gG_pzgfeESs">1</a><a href="https://www.youtube.com/watch?v=IKx49hjHDGc">2</a>], which we humans have been building since <a href="https://en.wikipedia.org/wiki/">1768</a>.</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[I don’t like robots that tell jokes. Humor is a complex concept and I don’t think humans fully understand how humor works. So trying to make robots say something funny feels wrong. I don’t like robots that dance. The robots are not as agile as we humans and every time I see dancing robots, they look like they don’t want to dance but were forced to do it. But we make them tell jokes or dance again, again, again, again, and again.]]></summary></entry><entry><title type="html">Implementing a finite state machine in Cycle.js</title><link href="/2018/11/08/implementing.html" rel="alternate" type="text/html" title="Implementing a finite state machine in Cycle.js" /><published>2018-11-08T08:00:00+00:00</published><updated>2018-11-08T08:00:00+00:00</updated><id>/2018/11/08/implementing</id><content type="html" xml:base="/2018/11/08/implementing.html"><![CDATA[<blockquote>
  <p><strong>Note:</strong> Check out other posts on programming a social robot using Cycle.js too:</p>
  <ol>
    <li><a href="/2018/11/01/programming.html">Programming a social robot using Cycle.js</a></li>
    <li><a href="/2018/11/08/implementing.html">Implementing a finite state machine in Cycle.js</a></li>
  </ol>
</blockquote>

<p>In this post, I’ll show you how to implement a reactive social robot program as a <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite state machine</a>. We’ll continue from where we left off in the previous post <a href="/2018/11/01/programming.html">Programming a social robot using Cycle.js</a>–so check it out if you haven’t already! If you are in a hurry, here is the <a href="https://stackblitz.com/edit/cycle-robot-drivers-tutorials-02-fsm">demo and complete code</a> of what we are building in this post.</p>

<h2 id="making-existing-travel-personality-quiz-program-more-complex">Making existing “travel personality quiz” program more complex</h2>

<p><a href="/2018/11/01/programming.html">Previously</a>, we programmed a <a href="https://github.com/mjyc/tablet-robot-face">tablet-face robot</a> to test your travel personality. Concretely, we implemented a tablet-face robot program that</p>

<ol>
  <li>looks at a person when it sees one and</li>
  <li>asks travel personality quiz questions as shown in <a href="http://www.nomadwallet.com/afford-travel-quiz-personality/">this flowchart</a></li>
</ol>

<p>as a <a href="https://cycle.js.org/">Cycle.js</a> application. Here are the <a href="https://stackblitz.com/edit/cycle-robot-drivers-tutorials-01-personality-quiz">demo</a> at Stackbliz and <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/01_personality_quiz">complete code</a> in GitHub from the previous post.</p>

<p><strong>IMPORTANT!!</strong> The main package we use in the demo and in this post, <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/run">cycle-robot-drivers/run</a>, only works on Chrome browsers  (&gt;= 65.0.3325.181) for now.</p>

<p>Now, what if we want the robot to</p>

<ol>
  <li>look at a person only when the robot is waiting for a person’s response,</li>
  <li>stop asking a question if the robot cannot see a person and resume asking the question if it sees a person again, and</li>
  <li>stop asking questions completely if a person abandons the robot, i.e., the robot does not see a person for more than 10 seconds.</li>
</ol>

<p>How difficult would it be to update the existing program to have these additional behaviors? Try implementing the new behaviors on top of the <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/01_personality_quiz/index.js">travel personality quiz program</a>.
What kind of challenges do you face?</p>

<p>From my experience, it was difficult to implement, or even just express the “stateful” behaviors in reactive programming. For example, to implement 1., I needed to know whether the robot is in the “waiting for a person’s response” state but it wasn’t clear how to represent such state in a scalable manner; I tried keeping all states in drivers (e.g., <code class="language-plaintext highlighter-rouge">SpeechRecognitionAction</code> emitting <code class="language-plaintext highlighter-rouge">status</code> events), as proxies (e.g., <code class="language-plaintext highlighter-rouge">$lastQuestion</code> in <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/01_personality_quiz/index.js#L58">the previous code</a>), or in higher-order streams, but none of them felt simple nor scalable. This was very concerning since <a href="http://wiki.ros.org/smach/Tutorials/Getting%20Started#Why_learn_Smach.3F">many</a> <a href="https://www.researchgate.net/figure/A-behavioral-state-machine-for-robot-soccer_fig10_238086654">robot</a> <a href="https://www.youtube.com/watch?v=4XEK7OU2gIw">behaviors</a> are expressed and implemented as stateful behaviors.</p>

<p>To address this problem, I propose using finite state machines to clearly express the desired robot behaviors. In the following, I first present a pattern for implementing a finite state machine in a reactive programming framework (Cycle.js) without scarifying maintainability. Then I demonstrate a use case of the FSM pattern via implementing the first additional behavior.</p>

<h2 id="what-is-a-finite-state-machine">What is a finite state machine?</h2>

<p>A <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite state machine (FSM)</a> is a computational model that can be used to represent and control execution flow. Due to their simplicity, FSMs have been frequently used by <a href="http://wiki.ros.org/smach">roboticists</a>, <a href="https://sketch.systems/">UI developers</a> and many others for a <a href="https://www.mtholyoke.edu/courses/pdobosh/cs100/handouts/genghis.pdf">long</a> <a href="http://www.inf.ed.ac.uk/teaching/courses/seoc/2005_2006/resources/statecharts.pdf">time</a>. An FSM we are using in this post is comprised of five parts:</p>

<ol>
  <li>A set of states, e.g., <code class="language-plaintext highlighter-rouge">'SAY_SENTENCE'</code>, <code class="language-plaintext highlighter-rouge">'WAIT_FOR_RESPONSE'</code>, etc.</li>
  <li>A set of variables, e.g., <code class="language-plaintext highlighter-rouge">currentSentence = 'Can you see yourself working online?'</code></li>
  <li>A set of inputs: e.g., <code class="language-plaintext highlighter-rouge">VALID_RESPONSE</code>, <code class="language-plaintext highlighter-rouge">INVALID_RESPONSE</code>, etc.</li>
  <li>A set of outputs: e.g., <code class="language-plaintext highlighter-rouge">speechSynthesisAction = 'Can you see yourself working online?'</code></li>
  <li>A transition function that takes a state, variable, and input and returns a state, variable, and output.</li>
</ol>

<p>If you are familiar with FSMs, the FSM we are using is a <a href="https://en.wikipedia.org/wiki/Mealy_machine">mealy machine</a> extended with “variables”.
Like a mealy machine, it has the following constraints:</p>

<ul>
  <li>the state set is a <a href="https://en.wikipedia.org/wiki/Finite_set">finite set</a></li>
  <li>the FSM can only be in one state at a time in the state set</li>
  <li>the transition function is deterministic; given a state, variable, and input the function always returns the same new state, new variable, and new output.</li>
</ul>

<h2 id="representing-the-travel-personality-quiz-program-as-an-fsm">Representing the “travel personality quiz” program as an FSM</h2>

<p>We’ll start from representing the <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/01_personality_quiz/index.js">“travel personality test” program</a> we implemented in the previous post as an FSM:</p>

<p><img src="https://thepracticaldev.s3.amazonaws.com/i/et73xk1bvd20kbyrt69c.png" alt="travel_personality_quiz_fsm" /></p>

<p>Here we have three states, <code class="language-plaintext highlighter-rouge">PEND</code>, <code class="language-plaintext highlighter-rouge">SAY</code>, <code class="language-plaintext highlighter-rouge">LISTEN</code>, and five input types, <code class="language-plaintext highlighter-rouge">START</code>, <code class="language-plaintext highlighter-rouge">SAY_DONE</code>, <code class="language-plaintext highlighter-rouge">VALID_RESPONSE</code>, <code class="language-plaintext highlighter-rouge">INVALID_RESPONSE</code>, and <code class="language-plaintext highlighter-rouge">DETECTED_FACE</code>. We omitted variables associated with each state and outputs associated with each transition for visual clarity.</p>

<p>Notice that we use verbs as state names (as a popular robotics FSM library <a href="http://wiki.ros.org/smach">SMACH</a> does). This is because we define the states based on distinct actions each state is performing, where the distinct actions are triggered by outputs emitted from transitions. You may have wondered why we did not create each state in the <a href="http://www.nomadwallet.com/afford-travel-quiz-personality/">travel quiz flowchart</a> as an individual state, e.g., <code class="language-plaintext highlighter-rouge">ASK_CAREER_QUESTION</code>, <code class="language-plaintext highlighter-rouge">ASK_WORKING_ABROAD_QUESTION</code>, <code class="language-plaintext highlighter-rouge">ASK_FAMILY_QUESTION</code>, etc. This is because representing the states that behave the same except the sentence the robot says with a single <code class="language-plaintext highlighter-rouge">SAY</code> state with a variable <code class="language-plaintext highlighter-rouge">currentSentence</code> (not shown in the diagram) yields the simpler, more maintainable FSM.</p>

<p>The inputs can be considered as the events that could occur in each state and  are originated from actions, e.g., <code class="language-plaintext highlighter-rouge">SAY_DONE</code>, sensors, e.g., <code class="language-plaintext highlighter-rouge">DETECTED_FACE</code>, or external systems, e.g. <code class="language-plaintext highlighter-rouge">START</code>. We represent an input as a type-value pair. For example, the <code class="language-plaintext highlighter-rouge">VALID_RESPONSE</code> type input is paired with a value “yes” or “no”, which is used to determine the transition between <code class="language-plaintext highlighter-rouge">LISTEN</code> to <code class="language-plaintext highlighter-rouge">SAY</code> (input values are not shown in the graph).</p>

<p>Now, let’s update the FSM to express the first additional behavior mentioned above: looking at a person only when the robot is waiting for a person’s response.</p>

<p><img src="https://thepracticaldev.s3.amazonaws.com/i/7z09n6fz5z1s8zjlb9ii.png" alt="travel_personality_quiz_fsm_updated" /></p>

<p>All we did here is remove the two self-loop transitions from the <code class="language-plaintext highlighter-rouge">PEND</code> and <code class="language-plaintext highlighter-rouge">SAY</code> states to stop the robot from looking at a person while the FSM is in those states.</p>

<h2 id="implementing-the-travel-personality-test-fsm-using-cyclejs">Implementing the “travel personality test” FSM using Cycle.js</h2>

<p>Let’s now implement the “travel personality test” FSM we defined above using Cycle.js.</p>

<p>First, we’ll try to define the FSM in javascript as follows:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">State</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">PEND</span><span class="p">:</span> <span class="dl">'</span><span class="s1">PEND</span><span class="dl">'</span><span class="p">,</span>
  <span class="na">SAY</span><span class="p">:</span> <span class="dl">'</span><span class="s1">SAY</span><span class="dl">'</span><span class="p">,</span>  <span class="c1">//_SENTENCE</span>
  <span class="na">LISTEN</span><span class="p">:</span> <span class="dl">'</span><span class="s1">LISTEN</span><span class="dl">'</span><span class="p">,</span>  <span class="c1">//_FOR_RESPONSE</span>
<span class="p">};</span>

<span class="kd">const</span> <span class="nx">InputType</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">START</span><span class="p">:</span> <span class="s2">`START`</span><span class="p">,</span>
  <span class="na">SAY_DONE</span><span class="p">:</span> <span class="s2">`SAY_DONE`</span><span class="p">,</span>
  <span class="c1">// QUIZ_DONE: is not an input type but a transition</span>
  <span class="na">VALID_RESPONSE</span><span class="p">:</span> <span class="s2">`VALID_RESPONSE`</span><span class="p">,</span>
  <span class="na">INVALID_RESPONSE</span><span class="p">:</span> <span class="s2">`INVALID_RESPONSE`</span><span class="p">,</span>
  <span class="na">DETECTED_FACE</span><span class="p">:</span> <span class="s2">`DETECTED_FACE`</span><span class="p">,</span>
<span class="p">};</span>

<span class="kd">function</span> <span class="nf">transition</span><span class="p">(</span><span class="nx">state</span><span class="p">,</span> <span class="nx">variables</span><span class="p">,</span> <span class="nx">input</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// a dummy transition function</span>
  <span class="kd">const</span> <span class="nx">newState</span> <span class="o">=</span> <span class="nx">state</span><span class="p">;</span>
  <span class="kd">const</span> <span class="nx">newVariables</span> <span class="o">=</span> <span class="nx">variables</span><span class="p">;</span>
  <span class="kd">const</span> <span class="nx">newOutputs</span> <span class="o">=</span> <span class="kc">null</span><span class="p">;</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="na">state</span><span class="p">:</span> <span class="nx">newState</span><span class="p">,</span>
    <span class="na">variables</span><span class="p">:</span> <span class="nx">newVariables</span><span class="p">,</span>
    <span class="na">outputs</span><span class="p">:</span> <span class="nx">newOutputs</span><span class="p">,</span>
  <span class="p">};</span>
<span class="p">}</span>

<span class="cm">/**
 * // Example state, variables, input, and outputs
 * const state = State.PEND;
 * const variables = {
 *   sentence: 'You are a vacationer!',
 * };
 * const input = {
 *   type: InputType.START,
 *   value: null,
 * };
 * const outputs = {
 *   SpeechSynthesisAction: {
 *     goal: 'You are a vacationer!'
 *   },
 *   SpeechRecognitionAction: {
 *     goal: {}
 *   },
 *   TabletFace: {
 *     goal: {
 *       type: 'SET_STATE',
 *       value: {
 *         leftEye: {x: 0.5, y: 0.5},
 *         rightEye: {x: 0.5, y: 0.5},
 *       },
 *     }},
 *   },
 * }
 */</span>
</code></pre></div></div>

<p>Here we define the set of states <code class="language-plaintext highlighter-rouge">State</code>, the set of input types <code class="language-plaintext highlighter-rouge">InputType</code>, and the transition function <code class="language-plaintext highlighter-rouge">transition</code>. The sets for the variables and outputs of the FSM are not explicitly defined, but I provided example values that the variables and outputs can take in the comment.</p>

<h3 id="setting-up-fsm-in-cyclejs">Setting up FSM in Cycle.js</h3>

<p>We’ll now setup the FSM as a Cycle.js application. You can fork <a href="https://stackblitz.com/edit/cycle-robot-drivers-tutorials-02-fsm">the Stackblitz demo code</a> and start coding or set up a Cycle.js application.
For the latter, create a folder:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir my-second-robot-program
cd my-second-robot-program
</code></pre></div></div>

<p>Download <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/02_fsm/package.json"><code class="language-plaintext highlighter-rouge">package.json</code></a>, <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/02_fsm/.babelrc"><code class="language-plaintext highlighter-rouge">.babelrc</code></a>, <a href="https://github.com/mjyc/cycle-robot-drivers/tree/master/examples/tutorials/02_fsm/index.html"><code class="language-plaintext highlighter-rouge">index.html</code></a>, create an empty <code class="language-plaintext highlighter-rouge">index.js</code> file in the folder, and run <code class="language-plaintext highlighter-rouge">npm install</code> to install the required npm packages. After installing, you can run <code class="language-plaintext highlighter-rouge">npm start</code> to build and start the web application–that does nothing at this point.</p>

<p>Now add the following code in <code class="language-plaintext highlighter-rouge">index.js</code>:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nx">xs</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">xstream</span><span class="dl">'</span><span class="p">;</span>
<span class="k">import</span> <span class="p">{</span><span class="nx">runRobotProgram</span><span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">@cycle-robot-drivers/run</span><span class="dl">'</span><span class="p">;</span>

<span class="kd">const</span> <span class="nx">State</span> <span class="o">=</span> <span class="p">{</span>
<span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">InputType</span> <span class="o">=</span> <span class="p">{</span>
<span class="c1">// ...</span>
<span class="kd">function</span> <span class="nf">transition</span><span class="p">(</span><span class="nx">state</span><span class="p">,</span> <span class="nx">variables</span><span class="p">,</span> <span class="nx">input</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// a dummy transition function</span>
<span class="c1">// ...</span>

<span class="kd">function</span> <span class="nf">input</span><span class="p">(</span>  <span class="c1">// a dummy input function</span>
  <span class="nx">start$</span><span class="p">,</span>
  <span class="nx">speechRecognitionActionResult$</span><span class="p">,</span>
  <span class="nx">speechSynthesisActionResult$</span><span class="p">,</span>
  <span class="nx">poses$</span><span class="p">,</span>
<span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">never</span><span class="p">();</span>
<span class="p">}</span>

<span class="kd">function</span> <span class="nf">output</span><span class="p">(</span><span class="nx">machine$</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// a dummy output function</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="na">SpeechSynthesisAction</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">never</span><span class="p">(),</span>
    <span class="na">SpeechRecognitionAction</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">never</span><span class="p">(),</span>
    <span class="na">TabletFace</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">never</span><span class="p">(),</span>
  <span class="p">};</span>
<span class="p">}</span>

<span class="kd">function</span> <span class="nf">main</span><span class="p">(</span><span class="nx">sources</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">const</span> <span class="nx">input$</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">TabletFace</span><span class="p">.</span><span class="nx">load</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">SpeechSynthesisAction</span><span class="p">.</span><span class="nx">result</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">SpeechRecognitionAction</span><span class="p">.</span><span class="nx">result</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">PoseDetection</span><span class="p">.</span><span class="nx">poses</span><span class="p">,</span>
  <span class="p">);</span>

  <span class="kd">const</span> <span class="nx">defaultMachine</span> <span class="o">=</span> <span class="p">{</span>
    <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">PEND</span><span class="p">,</span>
    <span class="na">variables</span><span class="p">:</span> <span class="p">{</span>
      <span class="na">sentence</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="na">outputs</span><span class="p">:</span> <span class="kc">null</span><span class="p">,</span>
  <span class="p">};</span>
  <span class="kd">const</span> <span class="nx">machine$</span> <span class="o">=</span> <span class="nx">input$</span><span class="p">.</span><span class="nf">fold</span><span class="p">((</span><span class="nx">machine</span><span class="p">,</span> <span class="nx">input</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="nf">transition</span><span class="p">(</span>
    <span class="nx">machine</span><span class="p">.</span><span class="nx">state</span><span class="p">,</span> <span class="nx">machine</span><span class="p">.</span><span class="nx">variables</span><span class="p">,</span> <span class="nx">input</span>
  <span class="p">),</span> <span class="nx">defaultMachine</span><span class="p">);</span>

  <span class="kd">const</span> <span class="nx">sinks</span> <span class="o">=</span> <span class="nf">output</span><span class="p">(</span><span class="nx">machine$</span><span class="p">);</span>
  <span class="k">return</span> <span class="nx">sinks</span><span class="p">;</span>
<span class="p">}</span>

<span class="nf">runRobotProgram</span><span class="p">(</span><span class="nx">main</span><span class="p">);</span>
</code></pre></div></div>

<p>If you run the application, it should load a robot face that still does nothing on your browser.</p>

<p>The most important thing to notice here is that we divide the <code class="language-plaintext highlighter-rouge">main</code> function into three functions; <code class="language-plaintext highlighter-rouge">input</code>, <code class="language-plaintext highlighter-rouge">transition</code>, and <code class="language-plaintext highlighter-rouge">output</code>. The <code class="language-plaintext highlighter-rouge">input</code> function takes incoming streams in <code class="language-plaintext highlighter-rouge">sources</code> and returns a stream that emits the FSM’s input values. We then use the <a href="https://github.com/staltz/xstream#fold"><code class="language-plaintext highlighter-rouge">fold</code></a> xstream operator on the returned stream (<code class="language-plaintext highlighter-rouge">$input</code>) to trigger the FSM’s <code class="language-plaintext highlighter-rouge">transition</code> function. Note that the <code class="language-plaintext highlighter-rouge">fold</code> operator is like <code class="language-plaintext highlighter-rouge">Array.prototype.reduce</code> for streams; it takes</p>

<ol>
  <li>an accumulator function that takes an emitted value (e.g., an FSM input value, <code class="language-plaintext highlighter-rouge">input</code>) and a previous output of the accumulator function (e.g., the latest FSM status, <code class="language-plaintext highlighter-rouge">machine</code>) or a seed value and</li>
  <li>an initial output of the accumulator function (e.g., the initial FSM status, <code class="language-plaintext highlighter-rouge">defaultMachine</code>).</li>
</ol>

<p>Finally, the <code class="language-plaintext highlighter-rouge">output</code> function takes the stream that emits FSM status (<code class="language-plaintext highlighter-rouge">$machine</code>) and returns outgoing streams.</p>

<h3 id="input-transition-and-output">Input, transition, and output</h3>

<p>Let’s implement the three functions.
First, update the dummy <code class="language-plaintext highlighter-rouge">input</code> function to:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">Response</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">YES</span><span class="p">:</span> <span class="dl">'</span><span class="s1">yes</span><span class="dl">'</span><span class="p">,</span>
  <span class="na">NO</span><span class="p">:</span> <span class="dl">'</span><span class="s1">no</span><span class="dl">'</span><span class="p">,</span>
<span class="p">}</span>

<span class="kd">function</span> <span class="nf">input</span><span class="p">(</span>
  <span class="nx">start$</span><span class="p">,</span>
  <span class="nx">speechRecognitionActionResult$</span><span class="p">,</span>
  <span class="nx">speechSynthesisActionResult$</span><span class="p">,</span>
  <span class="nx">poses$</span><span class="p">,</span>
<span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">merge</span><span class="p">(</span>
    <span class="nx">start$</span><span class="p">.</span><span class="nf">mapTo</span><span class="p">({</span><span class="na">type</span><span class="p">:</span> <span class="nx">InputType</span><span class="p">.</span><span class="nx">START</span><span class="p">}),</span>
    <span class="nx">speechRecognitionActionResult$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">result</span> <span class="o">=&gt;</span>
        <span class="nx">result</span><span class="p">.</span><span class="nx">status</span><span class="p">.</span><span class="nx">status</span> <span class="o">===</span> <span class="dl">'</span><span class="s1">SUCCEEDED</span><span class="dl">'</span>
        <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="nx">result</span><span class="p">.</span><span class="nx">result</span> <span class="o">===</span> <span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span> <span class="o">||</span> <span class="nx">result</span><span class="p">.</span><span class="nx">result</span> <span class="o">===</span> <span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">)</span>
      <span class="p">).</span><span class="nf">map</span><span class="p">(</span><span class="nx">result</span> <span class="o">=&gt;</span> <span class="p">({</span>
        <span class="na">type</span><span class="p">:</span> <span class="nx">InputType</span><span class="p">.</span><span class="nx">VALID_RESPONSE</span><span class="p">,</span>
        <span class="na">value</span><span class="p">:</span> <span class="nx">result</span><span class="p">.</span><span class="nx">result</span><span class="p">,</span>
      <span class="p">})),</span>
    <span class="nx">speechSynthesisActionResult$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">result</span> <span class="o">=&gt;</span> <span class="nx">result</span><span class="p">.</span><span class="nx">status</span><span class="p">.</span><span class="nx">status</span> <span class="o">===</span> <span class="dl">'</span><span class="s1">SUCCEEDED</span><span class="dl">'</span><span class="p">)</span>
      <span class="p">.</span><span class="nf">mapTo</span><span class="p">({</span><span class="na">type</span><span class="p">:</span> <span class="nx">InputType</span><span class="p">.</span><span class="nx">SAY_DONE</span><span class="p">}),</span>
    <span class="nx">speechRecognitionActionResult$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">result</span> <span class="o">=&gt;</span>
        <span class="nx">result</span><span class="p">.</span><span class="nx">status</span><span class="p">.</span><span class="nx">status</span> <span class="o">!==</span> <span class="dl">'</span><span class="s1">SUCCEEDED</span><span class="dl">'</span>
        <span class="o">||</span> <span class="p">(</span><span class="nx">result</span><span class="p">.</span><span class="nx">result</span> <span class="o">!==</span> <span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span> <span class="o">&amp;&amp;</span> <span class="nx">result</span><span class="p">.</span><span class="nx">result</span> <span class="o">!==</span> <span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">)</span>
      <span class="p">).</span><span class="nf">mapTo</span><span class="p">({</span><span class="na">type</span><span class="p">:</span> <span class="nx">InputType</span><span class="p">.</span><span class="nx">INVALID_RESPONSE</span><span class="p">}),</span>
    <span class="nx">poses$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">poses</span> <span class="o">=&gt;</span>
        <span class="nx">poses</span><span class="p">.</span><span class="nx">length</span> <span class="o">===</span> <span class="mi">1</span>
        <span class="o">&amp;&amp;</span> <span class="nx">poses</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">keypoints</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">kpt</span> <span class="o">=&gt;</span> <span class="nx">kpt</span><span class="p">.</span><span class="nx">part</span> <span class="o">===</span> <span class="dl">'</span><span class="s1">nose</span><span class="dl">'</span><span class="p">).</span><span class="nx">length</span> <span class="o">===</span> <span class="mi">1</span>
      <span class="p">).</span><span class="nf">map</span><span class="p">(</span><span class="nx">poses</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="kd">const</span> <span class="nx">nose</span> <span class="o">=</span> <span class="nx">poses</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">keypoints</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">kpt</span> <span class="o">=&gt;</span> <span class="nx">kpt</span><span class="p">.</span><span class="nx">part</span> <span class="o">===</span> <span class="dl">'</span><span class="s1">nose</span><span class="dl">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">];</span>
        <span class="k">return</span> <span class="p">{</span>
          <span class="na">type</span><span class="p">:</span> <span class="nx">InputType</span><span class="p">.</span><span class="nx">DETECTED_FACE</span><span class="p">,</span>
          <span class="na">value</span><span class="p">:</span> <span class="p">{</span>
            <span class="na">x</span><span class="p">:</span> <span class="nx">nose</span><span class="p">.</span><span class="nx">position</span><span class="p">.</span><span class="nx">x</span> <span class="o">/</span> <span class="mi">640</span><span class="p">,</span>  <span class="c1">// max value of position.x is 640</span>
            <span class="na">y</span><span class="p">:</span> <span class="nx">nose</span><span class="p">.</span><span class="nx">position</span><span class="p">.</span><span class="nx">y</span> <span class="o">/</span> <span class="mi">480</span><span class="p">,</span>  <span class="c1">// max value of position.y is 480</span>
          <span class="p">},</span>
        <span class="p">};</span>
      <span class="p">}),</span>
  <span class="p">);</span>
<span class="p">}</span>
<span class="c1">// ...</span>
</code></pre></div></div>

<p>Try testing whether the <code class="language-plaintext highlighter-rouge">input</code> function is behaving properly. For example, you can attach the <a href="https://github.com/staltz/xstream#addListener"><code class="language-plaintext highlighter-rouge">addListener</code></a> xstream operator to the returned <code class="language-plaintext highlighter-rouge">$input</code> stream and return some outgoing streams from the <code class="language-plaintext highlighter-rouge">output</code> function.
Like this:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ...</span>
<span class="k">import</span> <span class="nx">delay</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">xstream/extra/delay</span><span class="dl">'</span>
<span class="kd">function</span> <span class="nf">output</span><span class="p">(</span><span class="nx">machine$</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="na">SpeechSynthesisAction</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">of</span><span class="p">(</span><span class="dl">'</span><span class="s1">Hello world!</span><span class="dl">'</span><span class="p">).</span><span class="nf">compose</span><span class="p">(</span><span class="nf">delay</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>
    <span class="na">SpeechRecognitionAction</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">of</span><span class="p">({}).</span><span class="nf">compose</span><span class="p">(</span><span class="nf">delay</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>
    <span class="na">TabletFace</span><span class="p">:</span> <span class="nx">xs</span><span class="p">.</span><span class="nf">never</span><span class="p">(),</span>
  <span class="p">};</span>
<span class="p">}</span>

<span class="kd">function</span> <span class="nf">main</span><span class="p">(</span><span class="nx">sources</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">const</span> <span class="nx">input$</span> <span class="o">=</span> <span class="nf">input</span><span class="p">(</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">TabletFace</span><span class="p">.</span><span class="nx">load</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">SpeechSynthesisAction</span><span class="p">.</span><span class="nx">result</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">SpeechRecognitionAction</span><span class="p">.</span><span class="nx">result</span><span class="p">,</span>
    <span class="nx">sources</span><span class="p">.</span><span class="nx">PoseDetection</span><span class="p">.</span><span class="nx">poses</span><span class="p">,</span>
  <span class="p">);</span>
  <span class="nx">input$</span><span class="p">.</span><span class="nf">addListener</span><span class="p">({</span><span class="na">next</span><span class="p">:</span> <span class="nx">value</span> <span class="o">=&gt;</span> <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">'</span><span class="s1">input</span><span class="dl">'</span><span class="p">,</span> <span class="nx">value</span><span class="p">)})</span>
<span class="c1">// ...</span>
</code></pre></div></div>

<p>Do you see the expected outputs on your browser console? You should see many inputs with the <code class="language-plaintext highlighter-rouge">DETECTED_FACE</code> type if the robot is detecting a person.</p>

<p>Let’s now remove the dummy <code class="language-plaintext highlighter-rouge">transition</code> function and create a new one:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">State</span> <span class="o">=</span> <span class="p">{</span>
<span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">InputType</span> <span class="o">=</span> <span class="p">{</span>
<span class="c1">// ...</span>
<span class="c1">// // Remove the dummy transition function</span>
<span class="c1">// function transition(state, variables, input) {  // a dummy transition function</span>
<span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">Response</span> <span class="o">=</span> <span class="p">{</span>
<span class="c1">// ...</span>
<span class="kd">function</span> <span class="nf">input</span><span class="p">(</span>
<span class="c1">// ...</span>

<span class="kd">function</span> <span class="nf">createTransition</span><span class="p">()</span> <span class="p">{</span>
  <span class="kd">const</span> <span class="nx">Sentence</span> <span class="o">=</span> <span class="p">{</span>
    <span class="na">CAREER</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Is it important that you reach your full career potential?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">ONLINE</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Can you see yourself working online?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">FAMILY</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Do you have to be near my family/friends/pets?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">TRIPS</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Do you think short trips are awesome?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">HOME</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Do you want to have a home and nice things?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">ROUTINE</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Do you think a routine gives your life structure?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">JOB</span><span class="p">:</span> <span class="dl">'</span><span class="s1">Do you need a secure job and a stable income?</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">VACATIONER</span><span class="p">:</span> <span class="dl">'</span><span class="s1">You are a vacationer!</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">EXPAT</span><span class="p">:</span> <span class="dl">'</span><span class="s1">You are an expat!</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">NOMAD</span><span class="p">:</span> <span class="dl">'</span><span class="s1">You are a nomad!</span><span class="dl">'</span><span class="p">,</span>
  <span class="p">};</span>

  <span class="kd">const</span> <span class="nx">flowchart</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">CAREER</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">ONLINE</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">FAMILY</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">ONLINE</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">NOMAD</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">VACATIONER</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">FAMILY</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">VACATIONER</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">TRIPS</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">TRIPS</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">VACATIONER</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">HOME</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">HOME</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">EXPAT</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">ROUTINE</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">ROUTINE</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">EXPAT</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">JOB</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">Sentence</span><span class="p">.</span><span class="nx">JOB</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">YES</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">ONLINE</span><span class="p">,</span>
      <span class="p">[</span><span class="nx">Response</span><span class="p">.</span><span class="nx">NO</span><span class="p">]:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">NOMAD</span><span class="p">,</span>
    <span class="p">},</span>
  <span class="p">};</span>

  <span class="c1">// this transitionTable is a dictionary of dictionaries and returns a function</span>
  <span class="c1">//   that takes previous "variables" and "inputValue" and returns a current</span>
  <span class="c1">//   FSM status; {state, variable, outputs}</span>
  <span class="c1">// this transitionTable is a dictionary of dictionaries and returns a function</span>
  <span class="c1">//   that takes previous "variables" and "inputValue" and returns a current</span>
  <span class="c1">//   FSM status; {state, variable, outputs}</span>
  <span class="kd">const</span> <span class="nx">transitionTable</span> <span class="o">=</span> <span class="p">{</span>
    <span class="p">[</span><span class="nx">State</span><span class="p">.</span><span class="nx">PEND</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">InputType</span><span class="p">.</span><span class="nx">START</span><span class="p">]:</span> <span class="p">(</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInputValue</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">({</span>
        <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">SAY</span><span class="p">,</span>
        <span class="na">variables</span><span class="p">:</span> <span class="p">{</span><span class="na">sentence</span><span class="p">:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">CAREER</span><span class="p">},</span>
        <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span><span class="na">SpeechSynthesisAction</span><span class="p">:</span> <span class="p">{</span><span class="na">goal</span><span class="p">:</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">CAREER</span><span class="p">}},</span>
      <span class="p">}),</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">State</span><span class="p">.</span><span class="nx">SAY</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">InputType</span><span class="p">.</span><span class="nx">SAY_DONE</span><span class="p">]:</span> <span class="p">(</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInputValue</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">(</span>
          <span class="nx">prevVariables</span><span class="p">.</span><span class="nx">sentence</span> <span class="o">!==</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">VACATIONER</span>
          <span class="o">&amp;&amp;</span> <span class="nx">prevVariables</span><span class="p">.</span><span class="nx">sentence</span> <span class="o">!==</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">EXPAT</span>
          <span class="o">&amp;&amp;</span> <span class="nx">prevVariables</span><span class="p">.</span><span class="nx">sentence</span> <span class="o">!==</span> <span class="nx">Sentence</span><span class="p">.</span><span class="nx">NOMAD</span>
        <span class="p">)</span> <span class="p">?</span> <span class="p">{</span>  <span class="c1">// SAY_DONE</span>
          <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">LISTEN</span><span class="p">,</span>
          <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span>
          <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span><span class="na">SpeechRecognitionAction</span><span class="p">:</span> <span class="p">{</span><span class="na">goal</span><span class="p">:</span> <span class="p">{}}},</span>
        <span class="p">}</span> <span class="p">:</span> <span class="p">{</span>  <span class="c1">// QUIZ_DONE</span>
          <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">PEND</span><span class="p">,</span>
          <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span>
          <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span><span class="na">done</span><span class="p">:</span> <span class="kc">true</span><span class="p">},</span>
        <span class="p">},</span>
    <span class="p">},</span>
    <span class="p">[</span><span class="nx">State</span><span class="p">.</span><span class="nx">LISTEN</span><span class="p">]:</span> <span class="p">{</span>
      <span class="p">[</span><span class="nx">InputType</span><span class="p">.</span><span class="nx">VALID_RESPONSE</span><span class="p">]:</span> <span class="p">(</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInputValue</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">({</span>
        <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">SAY</span><span class="p">,</span>
        <span class="na">variables</span><span class="p">:</span> <span class="p">{</span><span class="na">sentence</span><span class="p">:</span> <span class="nx">flowchart</span><span class="p">[</span><span class="nx">prevVariables</span><span class="p">.</span><span class="nx">sentence</span><span class="p">][</span><span class="nx">prevInputValue</span><span class="p">]},</span>
        <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span>
          <span class="na">SpeechSynthesisAction</span><span class="p">:</span> <span class="p">{</span>
            <span class="na">goal</span><span class="p">:</span> <span class="nx">flowchart</span><span class="p">[</span><span class="nx">prevVariables</span><span class="p">.</span><span class="nx">sentence</span><span class="p">][</span><span class="nx">prevInputValue</span><span class="p">],</span>
          <span class="p">},</span>
          <span class="na">TabletFace</span><span class="p">:</span> <span class="p">{</span><span class="na">goal</span><span class="p">:</span> <span class="p">{</span>
            <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">SET_STATE</span><span class="dl">'</span><span class="p">,</span>
            <span class="na">value</span><span class="p">:</span> <span class="p">{</span>
              <span class="na">leftEye</span><span class="p">:</span> <span class="p">{</span><span class="na">x</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="na">y</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
              <span class="na">rightEye</span><span class="p">:</span> <span class="p">{</span><span class="na">x</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="na">y</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span>
            <span class="p">},</span>
          <span class="p">}},</span>
        <span class="p">},</span>
      <span class="p">}),</span>
      <span class="p">[</span><span class="nx">InputType</span><span class="p">.</span><span class="nx">INVALID_RESPONSE</span><span class="p">]:</span> <span class="p">(</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInputValue</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">({</span>
        <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">LISTEN</span><span class="p">,</span>
        <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span>
        <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span><span class="na">SpeechRecognitionAction</span><span class="p">:</span> <span class="p">{</span><span class="na">goal</span><span class="p">:</span> <span class="p">{}}},</span>
      <span class="p">}),</span>
      <span class="p">[</span><span class="nx">InputType</span><span class="p">.</span><span class="nx">DETECTED_FACE</span><span class="p">]:</span> <span class="p">(</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInputValue</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">({</span>
        <span class="na">state</span><span class="p">:</span> <span class="nx">State</span><span class="p">.</span><span class="nx">LISTEN</span><span class="p">,</span>
        <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span>
        <span class="na">outputs</span><span class="p">:</span> <span class="p">{</span>
          <span class="na">TabletFace</span><span class="p">:</span> <span class="p">{</span><span class="na">goal</span><span class="p">:</span> <span class="p">{</span>
            <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">SET_STATE</span><span class="dl">'</span><span class="p">,</span>
            <span class="na">value</span><span class="p">:</span> <span class="p">{</span>
              <span class="na">leftEye</span><span class="p">:</span> <span class="nx">prevInputValue</span><span class="p">,</span>
              <span class="na">rightEye</span><span class="p">:</span> <span class="nx">prevInputValue</span><span class="p">,</span>
            <span class="p">},</span>
          <span class="p">}},</span>
        <span class="p">}</span>
      <span class="p">}),</span>
    <span class="p">},</span>
  <span class="p">};</span>

  <span class="k">return</span> <span class="kd">function</span><span class="p">(</span><span class="nx">prevState</span><span class="p">,</span> <span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInput</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="nx">prevState</span><span class="p">,</span> <span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInput</span><span class="p">);</span>
    <span class="c1">// excuse me for abusing ternary</span>
    <span class="k">return</span> <span class="o">!</span><span class="nx">transitionTable</span><span class="p">[</span><span class="nx">prevState</span><span class="p">]</span>
      <span class="p">?</span> <span class="p">{</span><span class="na">state</span><span class="p">:</span> <span class="nx">prevState</span><span class="p">,</span> <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span> <span class="na">outputs</span><span class="p">:</span> <span class="kc">null</span><span class="p">}</span>
      <span class="p">:</span> <span class="o">!</span><span class="nx">transitionTable</span><span class="p">[</span><span class="nx">prevState</span><span class="p">][</span><span class="nx">prevInput</span><span class="p">.</span><span class="nx">type</span><span class="p">]</span>
        <span class="p">?</span> <span class="p">{</span><span class="na">state</span><span class="p">:</span> <span class="nx">prevState</span><span class="p">,</span> <span class="na">variables</span><span class="p">:</span> <span class="nx">prevVariables</span><span class="p">,</span> <span class="na">outputs</span><span class="p">:</span> <span class="kc">null</span><span class="p">}</span>
        <span class="p">:</span> <span class="nx">transitionTable</span><span class="p">[</span><span class="nx">prevState</span><span class="p">][</span><span class="nx">prevInput</span><span class="p">.</span><span class="nx">type</span><span class="p">](</span><span class="nx">prevVariables</span><span class="p">,</span> <span class="nx">prevInput</span><span class="p">.</span><span class="nx">value</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kd">const</span> <span class="nx">transition</span> <span class="o">=</span> <span class="nf">createTransition</span><span class="p">();</span>

<span class="kd">function</span> <span class="nf">output</span><span class="p">(</span><span class="nx">machine$</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// a dummy output function</span>
<span class="c1">// ...</span>
</code></pre></div></div>

<p>Here we define and return the FSM’s transition function inside the <code class="language-plaintext highlighter-rouge">createTransition</code> function.</p>

<p>Finally update the dummy <code class="language-plaintext highlighter-rouge">output</code> function to:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// ...</span>
<span class="kd">const</span> <span class="nx">transition</span> <span class="o">=</span> <span class="nf">createTransition</span><span class="p">();</span>

<span class="kd">function</span> <span class="nf">output</span><span class="p">(</span><span class="nx">machine$</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">const</span> <span class="nx">outputs$</span> <span class="o">=</span> <span class="nx">machine$</span>
    <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">machine</span> <span class="o">=&gt;</span> <span class="o">!!</span><span class="nx">machine</span><span class="p">.</span><span class="nx">outputs</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nx">machine</span> <span class="o">=&gt;</span> <span class="nx">machine</span><span class="p">.</span><span class="nx">outputs</span><span class="p">);</span>
  <span class="k">return</span> <span class="p">{</span>
    <span class="na">SpeechSynthesisAction</span><span class="p">:</span> <span class="nx">outputs$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">outputs</span> <span class="o">=&gt;</span> <span class="o">!!</span><span class="nx">outputs</span><span class="p">.</span><span class="nx">SpeechSynthesisAction</span><span class="p">)</span>
      <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nx">output</span> <span class="o">=&gt;</span> <span class="nx">output</span><span class="p">.</span><span class="nx">SpeechSynthesisAction</span><span class="p">.</span><span class="nx">goal</span><span class="p">),</span>
    <span class="na">SpeechRecognitionAction</span><span class="p">:</span> <span class="nx">outputs$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">outputs</span> <span class="o">=&gt;</span> <span class="o">!!</span><span class="nx">outputs</span><span class="p">.</span><span class="nx">SpeechRecognitionAction</span><span class="p">)</span>
      <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nx">output</span> <span class="o">=&gt;</span> <span class="nx">output</span><span class="p">.</span><span class="nx">SpeechRecognitionAction</span><span class="p">.</span><span class="nx">goal</span><span class="p">),</span>
    <span class="na">TabletFace</span><span class="p">:</span> <span class="nx">outputs$</span>
      <span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="nx">outputs</span> <span class="o">=&gt;</span> <span class="o">!!</span><span class="nx">outputs</span><span class="p">.</span><span class="nx">TabletFace</span><span class="p">)</span>
      <span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="nx">output</span> <span class="o">=&gt;</span> <span class="nx">output</span><span class="p">.</span><span class="nx">TabletFace</span><span class="p">.</span><span class="nx">goal</span><span class="p">),</span>
  <span class="p">};</span>
<span class="p">}</span>

<span class="kd">function</span> <span class="nf">main</span><span class="p">(</span><span class="nx">sources</span><span class="p">)</span> <span class="p">{</span>
<span class="c1">// ...</span>
</code></pre></div></div>

<p>Try running the application and test whether it behaves as we defined in the FSM.</p>

<p>You just implemented a social robot program as an FSM!</p>

<h4 id="relation-to-the-model-view-intent-pattern">Relation to the Model-View-Intent pattern</h4>

<p>The FSM pattern is an application of the <a href="https://cycle.js.org/model-view-intent.html">Model-View-Intent (MVI) pattern</a>, an <a href="https://cycle.js.org/model-view-intent.html#model-view-intent-what-mvc-is-really-about">adaptation of Model-View-Controller in reactive programming</a>, where “intent” is <code class="language-plaintext highlighter-rouge">input</code>, “model” is <code class="language-plaintext highlighter-rouge">FSM status</code>, and “view” is <code class="language-plaintext highlighter-rouge">output</code>. In addition to the MVI pattern, the FSM pattern additionally requires a specific structure for the “model”/<code class="language-plaintext highlighter-rouge">FSM status</code> and the “update”/<code class="language-plaintext highlighter-rouge">transition</code>.</p>

<h2 id="updating-the-travel-personality-quiz-fsm">Updating the “travel personality quiz” FSM</h2>

<p>The true power of the FSM pattern is its maintainability. The crux of the FSM pattern is dividing the <code class="language-plaintext highlighter-rouge">main</code> function into the three functions that have separate concerns:</p>

<ul>
  <li>the <code class="language-plaintext highlighter-rouge">input</code> function that focuses on turning incoming streams into “input” that the FSM can work with and</li>
  <li>the <code class="language-plaintext highlighter-rouge">transition</code> function implements the FSM’s transition function.</li>
  <li>the <code class="language-plaintext highlighter-rouge">output</code> function that maps the outputs returned from <code class="language-plaintext highlighter-rouge">transition</code> into the outgoing streams (<code class="language-plaintext highlighter-rouge">sinks</code> in Cycle.js) to make side effects, e.g., trigger actions.</li>
</ul>

<p>This separation allows programmers to only update the portion of code in the two functions when they need to make the program more complex.</p>

<p>For example, if we were to implement the rest of additional behaviors mentioned in the <a href="making-travel-personality-quiz-program-more-complex">Making “travel personality quiz” program more complex</a> section, we’ll need to first update the FSM to reflect the new desired behavior, e.g.:</p>

<p><img src="https://thepracticaldev.s3.amazonaws.com/i/st5hzvob4hq22pbrsb78.png" alt="travel_personality_quiz_fsm_final" /></p>

<p>and update the <code class="language-plaintext highlighter-rouge">input</code> and <code class="language-plaintext highlighter-rouge">transition</code> functions accordingly. Checkout the <a href="https://stackblitz.com/edit/cycle-robot-drivers-tutorials-02-fsm">complete code</a> to see how I updated the <code class="language-plaintext highlighter-rouge">input</code> and <code class="language-plaintext highlighter-rouge">transition</code> functions to implement the remaining additional behaviors.</p>

<p>The biggest challenge for using FSM is defining FSM. If you are using the FSM pattern and having problems with it, double check the current definition of your state machine. For example, look for the redundant states or input types that make updating the transition function cumbersome (merge them into one state with variables), or look for state or input type that is not being used as intended for (add new necessary states or input types). Another point to check is, making sure your FSM is taking reactive programming approach, e.g., make sure the three functions (<code class="language-plaintext highlighter-rouge">input</code>, <code class="language-plaintext highlighter-rouge">transition</code>, <code class="language-plaintext highlighter-rouge">output</code>) are as pure as possible. Defining effective FSM is art, but I believe using FSMs in reactive programming greatly helps the programmers to better organize their programs.</p>

<p>Thank you for reading! I hope I got you interested in using FSMs in Cycle.js. Let me know if something isn’t clear, and I’d be happy to chat.</p>

<p><em>My name is Mike Chung. I’m a <a href="https://homes.cs.washington.edu/~mjyc/">graduate student</a> interested in the field of human-robot interaction and machine learning. You can reach me on <a href="https://twitter.com/mjyc_">Twitter</a> and on <a href="https://github.com/mjyc">GitHub</a>.</em></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Note: Check out other posts on programming a social robot using Cycle.js too: Programming a social robot using Cycle.js Implementing a finite state machine in Cycle.js]]></summary></entry></feed>