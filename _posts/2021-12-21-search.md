---
layout: post
title: "In Search of Grammars of Robot Applications"
date: 2021-12-29 00:00:00 -0800
---

<p style="text-align: center"><img src="https://upload.wikimedia.org/wikipedia/commons/9/92/JOHN_COLTRANE.jpg" width="70%"></p>

I've been thinking about ways to make robot application programming easy[^1].
Here are my insights on the challenges in programming robot applications and my unfulfilled ideas for (dramatically) simplifying the process.

## Challenges with using existing robot behavior representations

In the past, I viewed a robot application as an application program that executes a (high-level) robot behavior.
The two most popular representations for implementing robot behaviors were (and still are) [finite-state machine](https://en.wikipedia.org/wiki/Finite-state_machine) (FSM) and [behavior tree](https://en.wikipedia.org/wiki/Behavior_tree_(artificial_intelligence,_robotics_and_control)) (BT).
Thus, programming robot applications usually meant programming FSMs or BTs.
In theory, FSMs or BTs are straightforward to program.
They have well-defined semantics (e.g., mathematical definitions), which makes them predictable and reasonable, and they natively support composition, enabling the creation of complex behaviors by reusing simpler ones.

Programming robot applications with FSMs or BTs wasn't so easy in practice.
The FSM and BT implementations I've met in the wild lacked clear semantics or gradually lost them over time, making them difficult to work with.
Frequently, I came across ill-defined transition functions that made it challenging to determine the triggers and conditions for transitions.
I often found side-effect-causing code snippets scattered across multiple states, used to force transitions or trigger actions instead of properly extending the transition function.
As a result, the FSMs became unpredictable and difficult to test.
Regarding BTs[^2], I encountered subtleties specific to the implementation or programming language, e.g., in how the execution logic handles the "tick," or misuses of BT features, e.g., abusing blackboard, that invariably led to complications.

Creating complex behaviors wasn't as easy as it appeared to be.
The most significant challenge I've faced was the maintenance of modules.
Driven by the composability of FSMs or BTs, developers often created intermediate FSM states or BT nodes (referred to as "modules") to represent simple skills or patterns.
While developers intended these modules to be reusable, without proper planning, it was all too easy to end up with numerous modules that hindered the creation of complex behaviors.

In most robotics (software) companies, the abovementioned challenges  weren't insurmountable.
Given the utmost importance of maintaining robust robot applications, companies could readily allocate ample resources to ensure the predictability and composability of FSMs and BTs.
This could be achieved through extensive discussions, refactoring, testing, and more.

<p style="text-align: center"><img src="http://wiki.ros.org/pr2_plugs_actions?action=AttachFile&amp;do=get&amp;target=smach.png" width="420px"></p>

FSMs and BTs have been serving the robotics community well, and likely, they will continue to do so, and yet, I didn't think using them was the future.
My primary concern with using FSMs and BTs was that they tend to nudge developers to view the robot as a solitary and central entity when determining the main flow of the application program (see the diagram above).
In the RaaS companies I worked at, robot applications almost always involved multiple robots, such as fleets of indoor mobile robots or lines of robot manipulators.
Even when the application focused on the behavior of a single robot, the underlying system was a distributed one comprising robotics services (e.g., perception, control) and external services (e.g., user interface, scheduler).
Consequently, application developers needed to think in terms of multiple robots or services and their interactions.
In such a context, it made more sense to regard a robot application as a program that implements the orchestration logic of a distributed system.


## Inspirations from non-robotics communities

When reactive programming was making a buzz in the WebDev community, I stumbled upon [Cycle.js](https://cycle.js.org/) and fell in love with it immediately.
I loved how Cycle.js' language-agnostic core concepts, like [functional reactive programming paradigm](https://dl.acm.org/doi/pdf/10.1145/258948.258973) and [ports and adaptors architecture](http://wiki.c2.com/?PortsAndAdaptersArchitecture), seemed to be transferrable to robot application programming.
I could imagine robot applications with complex interruption signals, e.g., consisting of external and internal signals like user input and system error signals, or more generally complex interaction flows, could be concisely expressed in a functional reactive programming paradigm.
By following ports and adaptors architecture, Cycle.js enforces a separation of side-effect-making code from the application logic, and it made testing a breeze, especially with [test tooling](https://rxjs.dev/guide/testing/marble-testing) that often came with reactive stream libraries like [ReactiveX](https://reactivex.io/).
It seemed that testing robot applications could benefit from such tooling as well.

Charmed by the initial impressions, I experimented with applying the core concepts from Cycle.js directly to robot application programming.
There were some initial successes.
It delivered on simplifying authoring complex interactive programs and testing such programs.
However, I eventually faced major challenges.
State management in Cycle.js-like frameworks was awkward, especially when it came to composing finite state machines, e.g., requiring techniques that are hard to get right, like [creating circular dependencies between streams](https://speakerdeck.com/p4checo/reactive-state-machines-using-feedback-loops), which was a showstopper because the creating FSMs must be well-supported for the robotics community.
Adopting Cycle.js' core concepts also didn't help much with the challenges of building robust applications for distributed robotics systems, such as dealing with unresponsive services, long-running/rare process crashes, and subtle performance regressions.
Given such experiences, I felt the strong need for a higher-level abstraction[^3] that allows developers to work directly in the application space without worrying about system-level problems.

Looking for new ideas, I explored tools and techniques from the DevOps community, known for their rich experiences working with (large) distributed systems.
The community's proficiency in employing the declarative approach, i.e., describing the desired state and automating the remaining steps, emphasizing on robustness and resilience, was evident in tools (e.g., [Kubernetes](https://kubernetes.io/)) and processes (e.g., [GitOps](https://about.gitlab.com/topics/gitops/)).
I liked what I found, but it wasn't immediately apparent how to apply these findings to the domain of robot application programming.
At the time (2017~2018), DevOps tools were primarily tailored to specific environments (e.g., the cloud) and technologies (e.g., containers) that were foreign to robotics systems.
Nevertheless, as DevOps is a methodology, adopting its practices in the robotics domain has been ongoing[^4].
I hope to catch up and revisit the adoption in a future post.

Perhaps the biggest inspiration came from the [grammar of graphics](https://wiki.c2.com/?TheGrammarOfGraphics).
The graphics of grammar offered a concise and structured way to build and explore a large space of data visualization quickly.
There are three core layers of the graphics of grammar:

1. _Data_ is a data frame containing one or more variables. Fundamentally, data represents categorizable inputs to a visualization system.
2. _Aesthetic_ defines a mapping one or more variables to one or more visual elements. Fundamentally, Aesthetic maps the categorizable inputs to entities in the application space.
3. _Geometry_ decides the type or shape of the visual elements. Fundamentally, Geometry gives precise meanings to the mapped entities.

We can apply the fundamental structure to the robot application programming domain, for example:

1. _Robot layout_ defines the physical arrangement of robots and other structures, for example, a layout of a manufacturing line and robot cells.
2. _Task mapping_ defines how robots and devices map to particular tasks, e.g., insertion, inspection, etc.
3. _Task detailing_ defines details of the assigned tasks, possibly even the interaction of multiple robots and devices.

It's a rudimentary idea, but one can imagine defining a grammar or [declarative specification](https://vega.github.io/vega-lite/) that can express the space of particular robot applications, e.g., the space of manufacturing line applications or the space of indoor delivery applications.
Then, the task of developers or solution engineers would be to write a configuration that precisely describes a particular application in mind.
Construction of such a grammar will be nontrivial.
It will require deep understanding and careful organization of the application that will require collaboration with domain experts per application domain.
However, I believe this is the direction that can accelerate the adoption of intelligent robotics services in the target industry.

## Closing note

I wrote this post to share the idea that I'm excited about--the grammar of robot applications--in its very early form because I likely won't have time to work on it.
But this post wasn't just about that.
I shared my observations on the challenges associated with robot application programming and things I've tried, e.g., applying tools and techniques from other communities.
I hope this post inspired readers to consider taking cross-over approaches to tackle their hard (robotics) problems, if makes sense.

[^1] I wrote a [thesis](https://mjyc.github.io/assets/pdfs/PhD%20Thesis%20-%20Michael%20Jae-Yoon%20Chung.pdf) on this topic; this post shares a series of incomplete projects that didn't fit.
<br>[^2] For more insights, checkout [Overcoming Pitfalls in Behavior Tree Design](http://www.gameaipro.com/GameAIPro3/GameAIPro3_Chapter09_Overcoming_Pitfalls_in_Behavior_Tree_Design.pdf).
<br>[^3] To this end, I've tried [creating a higher-level DSL](https://mjyc.github.io/assets/pdfs/chung2022soboro.pdf) and [applying program synthesis](https://mjyc.github.io/assets/pdfs/chung2022authoring.pdf).
<br>[^4] [awesome-cloud-robotics](https://github.com/Airbotics/awesome-cloud-robotics) gives some idea.